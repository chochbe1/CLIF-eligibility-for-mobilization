{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c695437",
   "metadata": {
    "papermill": {
     "duration": 0.020666,
     "end_time": "2025-05-05T20:35:54.770979",
     "exception": false,
     "start_time": "2025-05-05T20:35:54.750313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Eligibility for mobilization - Analysis\n",
    "\n",
    "Run this script after running the [cohort_identification.ipynb](cohort_identification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbe3c9",
   "metadata": {
    "papermill": {
     "duration": 0.008986,
     "end_time": "2025-05-05T20:35:54.792613",
     "exception": false,
     "start_time": "2025-05-05T20:35:54.783627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d90660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:35:54.810382Z",
     "iopub.status.busy": "2025-05-05T20:35:54.810138Z",
     "iopub.status.idle": "2025-05-05T20:35:56.197661Z",
     "shell.execute_reply": "2025-05-05T20:35:56.197341Z"
    },
    "papermill": {
     "duration": 1.398106,
     "end_time": "2025-05-05T20:35:56.198508",
     "exception": false,
     "start_time": "2025-05-05T20:35:54.800402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install pandas numpy duckdb seaborn matplotlib tableone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from tableone import TableOne\n",
    "import pyCLIF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import UpSet, from_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b875e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:35:56.225641Z",
     "iopub.status.busy": "2025-05-05T20:35:56.225435Z",
     "iopub.status.idle": "2025-05-05T20:35:56.465776Z",
     "shell.execute_reply": "2025-05-05T20:35:56.465409Z"
    },
    "papermill": {
     "duration": 0.248165,
     "end_time": "2025-05-05T20:35:56.466870",
     "exception": false,
     "start_time": "2025-05-05T20:35:56.218705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = pd.read_parquet('../output/intermediate/final_df_hourly.parquet')\n",
    "all_ids_w_outcome = pd.read_parquet('../output/intermediate/cohort_all_ids_w_outcome.parquet')\n",
    "final_df_blocks = pd.read_parquet('../output/intermediate/final_df_blocks.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3306bc",
   "metadata": {
    "papermill": {
     "duration": 0.005779,
     "end_time": "2025-05-05T20:35:56.478753",
     "exception": false,
     "start_time": "2025-05-05T20:35:56.472974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Forward and Backward fill the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852cfac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:35:56.491542Z",
     "iopub.status.busy": "2025-05-05T20:35:56.491380Z",
     "iopub.status.idle": "2025-05-05T20:35:56.633482Z",
     "shell.execute_reply": "2025-05-05T20:35:56.632837Z"
    },
    "papermill": {
     "duration": 0.151546,
     "end_time": "2025-05-05T20:35:56.636176",
     "exception": false,
     "start_time": "2025-05-05T20:35:56.484630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "before_filling = final_df.isnull().sum() / len(final_df) * 100\n",
    "print(\"Shape of final_df: \", final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d9ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:35:56.651160Z",
     "iopub.status.busy": "2025-05-05T20:35:56.650747Z",
     "iopub.status.idle": "2025-05-05T20:36:08.998861Z",
     "shell.execute_reply": "2025-05-05T20:36:08.998491Z"
    },
    "papermill": {
     "duration": 12.356486,
     "end_time": "2025-05-05T20:36:08.999951",
     "exception": false,
     "start_time": "2025-05-05T20:35:56.643465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0 ── safety ordering ───────────────────────────────────────\n",
    "final_df = final_df.sort_values(\n",
    "    by=['encounter_block', 'recorded_date', 'recorded_hour']\n",
    ")\n",
    "\n",
    "# 1 ── identify column groups ────────────────────────────────\n",
    "flag_columns = [\n",
    "    'hourly_trach','hourly_on_vent','nicardipine_flag','nitroprusside_flag',\n",
    "    'clevidipine_flag','red_meds_flag','cisatracurium_flag','vecuronium_flag',\n",
    "    'rocuronium_flag','paralytics_flag'\n",
    "]\n",
    "exclude_columns = [\n",
    "    'patient_id','hospitalization_id','encounter_block',\n",
    "     'recorded_date','recorded_hour',\n",
    "    'time_from_vent','time_from_vent_adjusted', 'lactate',\n",
    "    'last_ne_dose_last_6_hours','ne_calc_last']\n",
    "\n",
    "all_cols           = set(final_df.columns)\n",
    "potential_fill     = all_cols - set(flag_columns) - set(exclude_columns) \n",
    "continuous_columns = [\n",
    "    c for c in potential_fill\n",
    "    if pd.api.types.is_numeric_dtype(final_df[c])\n",
    "]\n",
    "\n",
    "# 2 ── binary flags → 0/1 ints ───────────────────────────────\n",
    "for col in flag_columns:\n",
    "    final_df[col] = final_df[col].fillna(0).astype(int)\n",
    "\n",
    "# 3 ── forward / backward fill for numeric variables ---------\n",
    "final_df[continuous_columns] = (\n",
    "    final_df\n",
    "      .groupby('encounter_block')[continuous_columns]\n",
    "      .transform(lambda s: s.ffill().bfill())\n",
    ")\n",
    "\n",
    "# 4 ── lactate: forward-fill but **only 24 h** (24 rows) -----\n",
    "final_df['lactate'] = (\n",
    "    final_df\n",
    "      .groupby('encounter_block')\n",
    "      .apply(lambda g: g['lactate'].fillna(method='ffill', limit=24))\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# 5 ── tracheostomy flag stays 1 once first seen -------------\n",
    "final_df['hourly_trach'] = (\n",
    "    final_df.groupby('encounter_block')['hourly_trach']\n",
    "            .transform(lambda s: s.cummax())\n",
    "            .astype(int)\n",
    ")\n",
    "\n",
    "final_df['ne_calc_last'] = (\n",
    "    final_df\n",
    "      .groupby('encounter_block')['ne_calc_last']\n",
    "      .transform(lambda s: s.ffill())\n",
    ")\n",
    "\n",
    "\n",
    "# 6 ── norepinephrine: exact-6-hour look-backs, but\n",
    "#     **only replace rows that were NA already**\n",
    "# ------------------------------------------------\n",
    "def add_exact_6h_ne(block: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    • If a row already has last_ne_dose_last_6_hours \n",
    "      it is **left unchanged**.\n",
    "    • Otherwise we insert the value from 6 hours earlier\n",
    "      (0 if no row exists 6 hours before).\n",
    "    Expect *block* to be time-sorted.\n",
    "    \"\"\"\n",
    "    block = block.copy()\n",
    "\n",
    "    # make sure the columns exist\n",
    "    if 'last_ne_dose_last_6_hours' not in block.columns:\n",
    "        block[col] = np.nan\n",
    "\n",
    "    # candidate fill values = value 6 rows earlier\n",
    "    fill_last = block['ne_calc_last'].shift(6)\n",
    "\n",
    "    # only overwrite where current value is NA\n",
    "    block.loc[block['last_ne_dose_last_6_hours'].isna(), 'last_ne_dose_last_6_hours'] = fill_last\n",
    "\n",
    "    # still-missing ⇒ 0  (= “no vasopressor recorded 6 h ago”)\n",
    "    block[['last_ne_dose_last_6_hours']] = block[[\n",
    "               'last_ne_dose_last_6_hours']].fillna(0)\n",
    "\n",
    "    return block\n",
    "\n",
    "\n",
    "final_df = (\n",
    "    final_df\n",
    "      .sort_values(['encounter_block', 'recorded_date', 'recorded_hour']) \n",
    "      .groupby('encounter_block', group_keys=False)\n",
    "      .apply(add_exact_6h_ne)\n",
    "      .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a1f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:09.013704Z",
     "iopub.status.busy": "2025-05-05T20:36:09.013550Z",
     "iopub.status.idle": "2025-05-05T20:36:09.176809Z",
     "shell.execute_reply": "2025-05-05T20:36:09.176164Z"
    },
    "papermill": {
     "duration": 0.171152,
     "end_time": "2025-05-05T20:36:09.177821",
     "exception": false,
     "start_time": "2025-05-05T20:36:09.006669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "after_filling = final_df.isnull().sum() / len(final_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_after = pd.DataFrame({\n",
    "    'before_filling': before_filling,\n",
    "    'after_filling': after_filling\n",
    "}).reset_index()\n",
    "before_after = before_after.rename(columns={'index': 'column'})\n",
    "# save before_after to csv\n",
    "before_after.to_csv('../output/final/missingness_final_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac381b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:09.191606Z",
     "iopub.status.busy": "2025-05-05T20:36:09.191454Z",
     "iopub.status.idle": "2025-05-05T20:36:10.106927Z",
     "shell.execute_reply": "2025-05-05T20:36:10.106580Z"
    },
    "papermill": {
     "duration": 0.923458,
     "end_time": "2025-05-05T20:36:10.107871",
     "exception": false,
     "start_time": "2025-05-05T20:36:09.184413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint- useful to compare to the original df and check filling logic\n",
    "final_df.to_parquet(f'../output/intermediate/final_df_filled.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07786367",
   "metadata": {
    "papermill": {
     "duration": 0.005973,
     "end_time": "2025-05-05T20:36:10.120420",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.114447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Criteria Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc68edf",
   "metadata": {
    "papermill": {
     "duration": 0.00623,
     "end_time": "2025-05-05T20:36:10.132516",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.126286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Patel et al. Criteria:\n",
    "\n",
    "Cardio\n",
    "* Mean arterial blood pressure: 65-110 mm Hg\n",
    "* Systolic blood pressure: ≤ 200 mm Hg\n",
    "* Heart rate: 40-130 beats per minute\n",
    "\n",
    "Respiratory\n",
    "* Respiratory rate: 5-40 breaths per minute\n",
    "* Pulse oximetry: ≥ 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2aca63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:10.145371Z",
     "iopub.status.busy": "2025-05-05T20:36:10.145192Z",
     "iopub.status.idle": "2025-05-05T20:36:10.181168Z",
     "shell.execute_reply": "2025-05-05T20:36:10.180771Z"
    },
    "papermill": {
     "duration": 0.043514,
     "end_time": "2025-05-05T20:36:10.182200",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.138686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Patel et al. Criteria\n",
    "\n",
    "# 1. Mean arterial blood pressure: 65-110 mm Hg\n",
    "## 5/5/25 -- UPDATE MAP TO CONSIDER AVERAGE VALUE BASED ON VASOPRESSOR DOSE\n",
    "# final_df['patel_map_flag'] = (\n",
    "#     (final_df['min_map'] >= 65) & (final_df['max_map'] <= 110)\n",
    "# ).astype(int)\n",
    "\n",
    "final_df['patel_map_flag'] = (\n",
    "    (final_df['avg_map'] >= 65) & (final_df['avg_map'] <= 110)\n",
    ").astype(int)\n",
    "\n",
    "# 2. Systolic blood pressure: ≤ 200 mm Hg\n",
    "final_df['patel_sbp_flag'] = (\n",
    "    final_df['max_sbp'].isna() |\n",
    "    (final_df['max_sbp'] <= 200)\n",
    ").astype(int)\n",
    "\n",
    "# 3. Heart rate (Pulse): 40-130 beats per minute\n",
    "final_df['patel_pulse_flag'] = (\n",
    "    (final_df['min_heart_rate'] >= 40) & (final_df['max_heart_rate'] <= 130)\n",
    ").astype(int)\n",
    "\n",
    "# 4. Respiratory rate: 5-40 breaths per minute\n",
    "final_df['patel_resp_rate_flag'] = (\n",
    "    (final_df['min_respiratory_rate'] >= 5) & (final_df['max_respiratory_rate'] <= 40)\n",
    ").astype(int)\n",
    "\n",
    "# 5. Pulse oximetry (SpO2): ≥ 88%\n",
    "final_df['patel_spo2_flag'] = (\n",
    "    final_df['min_spo2'].isna() |\n",
    "    (final_df['min_spo2'] >= 88)\n",
    ").astype(int)\n",
    "\n",
    "# Resp flag: Combines respiratory rate and SpO2 criteria\n",
    "final_df['patel_resp_flag'] = (\n",
    "    final_df['patel_resp_rate_flag'] &\n",
    "    final_df['patel_spo2_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "# Cardio flag: Combines MAP, SBP, and Pulse criteria\n",
    "final_df['patel_cardio_flag'] = (\n",
    "    final_df['patel_map_flag'] &\n",
    "    final_df['patel_sbp_flag'] &\n",
    "    final_df['patel_pulse_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "# Create the overall Patel flag\n",
    "final_df['patel_flag'] = (\n",
    "    final_df['patel_map_flag'] &\n",
    "    final_df['patel_sbp_flag'] &\n",
    "    final_df['patel_pulse_flag'] &\n",
    "    final_df['patel_resp_rate_flag'] &\n",
    "    final_df['patel_spo2_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['patel_flag_all_hours'] = (\n",
    "    final_df['patel_map_flag'] &\n",
    "    final_df['patel_sbp_flag'] &\n",
    "    final_df['patel_pulse_flag'] &\n",
    "    final_df['patel_resp_rate_flag'] &\n",
    "    final_df['patel_spo2_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3177f",
   "metadata": {
    "papermill": {
     "duration": 0.006093,
     "end_time": "2025-05-05T20:36:10.194856",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.188763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TEAM criteria\n",
    "\n",
    "Cardio\n",
    "* Heart rate: ≤ 150 bpm\n",
    "* Most recent lactate: ≤ 4.0 mmol/L\n",
    "* Noradrenaline infusion rate: <0.2 mcg/kg/min or if infusion rate has increased by more than 25% in the last 6 hours, dose must be <0.1 mcg/kg/min.\n",
    "Respiratory\n",
    "* Sufficient respiratory stability:\n",
    "    *  FiO2: ≤ 0.6\n",
    "    *  PEEP: ≤ 16 cm H2O (use peep_observed)\n",
    "* Current respiratory rate: ≤ 45 (use resp_rate_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75262f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:10.207774Z",
     "iopub.status.busy": "2025-05-05T20:36:10.207610Z",
     "iopub.status.idle": "2025-05-05T20:36:10.271977Z",
     "shell.execute_reply": "2025-05-05T20:36:10.271534Z"
    },
    "papermill": {
     "duration": 0.07213,
     "end_time": "2025-05-05T20:36:10.272954",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.200824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Heart rate: ≤ 150 bpm\n",
    "final_df['team_pulse_flag'] = np.where(\n",
    "    final_df['max_heart_rate'].isna(),\n",
    "    1,\n",
    "    (final_df['max_heart_rate'] <= 150).astype(int)\n",
    ")\n",
    "\n",
    "# 2. Most recent lactate: ≤ 4.0 mmol/L\n",
    "final_df['team_lactate_flag'] = np.where(\n",
    "    final_df['lactate'].isna(),\n",
    "    1,\n",
    "    (final_df['lactate'] <= 4.0).astype(int)\n",
    ")\n",
    "\n",
    "# 3. Noradrenaline infusion rate: <0.2 mcg/kg/min \n",
    "# final_df['team_ne_flag'] = np.where(\n",
    "#     final_df['ne_calc_max'].isna(),\n",
    "#     1,\n",
    "#     (final_df['ne_calc_max'] <= 0.2).astype(int)\n",
    "# )\n",
    "\n",
    "# final_df['team_ne_flag'] = (\n",
    "#     # (final_df['ne_calc_min'] >= 0.1) & (final_df['ne_calc_max'] <= 0.2)\n",
    "#     final_df['ne_calc_max'] <= 0.2\n",
    "# ).astype(int)\n",
    "\n",
    "# print the number of team_ne_flag == 1\n",
    "# print(\"TEAM NE flag counts when ne < 0.2\\n\", final_df['team_ne_flag'].value_counts(), \"\\n\")\n",
    " \n",
    "# #3b. set the flag to 0 if infusion rate has increased by more than 25% in the last 6 hours and the dose is >0.1 mcg/kg/min.\n",
    "# final_df['team_ne_flag'] = np.where(\n",
    "#     (final_df['ne_calc_max'] > 1.25 * final_df['min_ne_dose_last_6_hours']) & (final_df['ne_calc_max'] > 0.1),\n",
    "#     0,\n",
    "#     final_df['team_ne_flag']\n",
    "# )\n",
    "\n",
    "\n",
    "final_df['team_ne_flag'] = np.where(\n",
    "    final_df['ne_calc_last'].isna(),\n",
    "    1,\n",
    "    (final_df['ne_calc_last'] <= 0.2).astype(int)\n",
    ")\n",
    "\n",
    "# print the number of team_ne_flag == 1\n",
    "print(\"TEAM NE flag counts when ne < 0.2\\n\", final_df['team_ne_flag'].value_counts(), \"\\n\")\n",
    " \n",
    "#3b. set the flag to 0 if infusion rate has increased by more than 25% in the last 6 hours and the dose is >0.1 mcg/kg/min.\n",
    "final_df['team_ne_flag'] = np.where(\n",
    "    (final_df['ne_calc_last'] > 1.25 * final_df['last_ne_dose_last_6_hours']) & (final_df['ne_calc_last'] > 0.1),\n",
    "    0,\n",
    "    final_df['team_ne_flag']\n",
    ")\n",
    "print(\"TEAM NE flag counts adjusting for change in the last 6 hrs\\n\", final_df['team_ne_flag'].value_counts(), \"\\n\")\n",
    "\n",
    "# 4. Sufficient respiratory stability:\n",
    "#    a. FiO2: ≤ 0.6\n",
    "final_df['team_fio2_flag'] = np.where(\n",
    "    final_df['min_fio2_set'].isna(),\n",
    "    1,\n",
    "    (final_df['min_fio2_set'] <= 0.6).astype(int)\n",
    ")\n",
    "\n",
    "#    b. PEEP: ≤ 16 cm H2O\n",
    "final_df['team_peep_flag'] = np.where(\n",
    "    final_df['max_peep_set'].isna(),\n",
    "    1,\n",
    "    (final_df['max_peep_set'] <= 16).astype(int)\n",
    ")\n",
    "\n",
    "# 5. Current respiratory rate: ≤ 45\n",
    "final_df['team_resp_rate_flag'] = np.where(\n",
    "    final_df['max_respiratory_rate'].isna(),\n",
    "    1,\n",
    "    (final_df['max_respiratory_rate'] <= 45).astype(int)\n",
    ")\n",
    "\n",
    "# Cardio flag: Combines heart rate, lactate, and norepinephrine criteria\n",
    "final_df['team_cardio_flag'] = (\n",
    "    final_df['team_pulse_flag'] &\n",
    "    final_df['team_lactate_flag'] &\n",
    "    final_df['team_ne_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "# Resp flag: Combines FiO2, PEEP, and respiratory rate criteria\n",
    "final_df['team_resp_flag'] = (\n",
    "    final_df['team_fio2_flag'] &\n",
    "    final_df['team_peep_flag'] &\n",
    "    final_df['team_resp_rate_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# Create the overall TEAM flag\n",
    "final_df['team_flag'] = (\n",
    "    final_df['team_pulse_flag'] &\n",
    "    final_df['team_lactate_flag'] &\n",
    "    final_df['team_ne_flag'] &\n",
    "    final_df['team_fio2_flag'] &\n",
    "    final_df['team_peep_flag'] &\n",
    "    final_df['team_resp_rate_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) & \n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['team_flag_all_hours'] = (\n",
    "    final_df['team_pulse_flag'] &\n",
    "    final_df['team_lactate_flag'] &\n",
    "    final_df['team_ne_flag'] &\n",
    "    final_df['team_fio2_flag'] &\n",
    "    final_df['team_peep_flag'] &\n",
    "    final_df['team_resp_rate_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) & \n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647de90e",
   "metadata": {
    "papermill": {
     "duration": 0.006015,
     "end_time": "2025-05-05T20:36:10.285433",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.279418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Consensus criteria\n",
    "\n",
    "* Green Criteria\n",
    "    * Respiratory\n",
    "        * Saturation  90% and\n",
    "        * Respiratory rate ≤ 30 breaths/min\n",
    "        * Current FiO2 ≤ 0.6 and\n",
    "        * PEEP≤ 10cm H20\n",
    "    * Cardiovascular:\n",
    "        * Blood pressure greater than lower limit of target range (MAP 65+) while on no or low level of support (low support- define as <0.1 μg/kg/min of Norepi equivalents)\n",
    "        * Heart rate <120 beats/min\n",
    "        * lactate < 4mmol/L\n",
    "        * HR > 40\n",
    "* Yellow Criteria\n",
    "    * Respiratory\n",
    "        * Sat >= 90%\n",
    "        * Current FiO2 >0.6\n",
    "        * Respiratory rate >30breaths/min\n",
    "        * PEEP >10cm H20\n",
    "    * Cardiovascular\n",
    "        * Blood pressure greater than lower limit of target range (MAP 65+) while receiving moderate level of support (medium-define as 0.1–0.3 μg/kg/min of Norepi equivalents)\n",
    "        * Heart rate 120-150 beats/min\n",
    "        * Shock of any cause with lactate >4mmol/L\n",
    "        * HR > 40\n",
    "* Red Criteria\n",
    "    * Respiratory\n",
    "        * Sat <90%\n",
    "    * Cardiovascular\n",
    "        * Below target MAP despite support (MAP <65) or\n",
    "        * greater than lower limit MAP (MAP 65+) but on high level support (high defined as >0.3 μg/kg/min of Norepi equivalents)\n",
    "        * IV therapy for hypertensive emergency (SBP >200mmHg or MAP >110 and on nicardipine, nitroprusside, or clevidipine gtt)\n",
    "        * HR >150 bpm\n",
    "        * Bradycardia <40\n",
    "\n",
    "\n",
    "**Consensus criteria - redefined**\n",
    "\n",
    "* all_red: All red subcomponents must be met.\n",
    "* all_green: All green subcomponents must be met, and no red subcomponents are met.\n",
    "* all_yellow: All yellow subcomponents must be met, no red subcomponents are met, and all green subcomponents are not met.\n",
    "* any_yellow: Any yellow subcomponent is met, no green subcomponents are fully met, and no red subcomponents are met.\n",
    "* any_yellow_or_green_no_red: Any yellow or green subcomponents are met, but no red subcomponents are met.\n",
    "* no_red: No red criteria is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0053da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:10.299060Z",
     "iopub.status.busy": "2025-05-05T20:36:10.298886Z",
     "iopub.status.idle": "2025-05-05T20:36:10.493923Z",
     "shell.execute_reply": "2025-05-05T20:36:10.493543Z"
    },
    "papermill": {
     "duration": 0.20315,
     "end_time": "2025-05-05T20:36:10.495001",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.291851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Red Cardiovascular Criteria\n",
    "final_df['red_resp_spo2_flag'] = ((final_df['min_spo2'] < 90) | final_df['min_spo2'].isna()).astype(int)\n",
    "final_df['red_map_flag'] = ((final_df['avg_map'] < 65) | final_df['avg_map'].isna()).astype(int)\n",
    "\n",
    "# High support (Norepinephrine equivalents > 0.3 μg/kg/min)\n",
    "final_df['red_high_support_flag'] = ((final_df['ne_calc_last'] > 0.3)).astype(int)\n",
    "\n",
    "# Hypertensive emergency criteria (SBP > 200 mmHg or MAP > 110 mmHg and on certain medications)\n",
    "final_df['red_hypertensive_flag'] = (\n",
    "    (((final_df['max_sbp'] > 200) | (final_df['avg_map'] > 110)) &\n",
    "    (final_df['red_meds_flag'] == 1)) \n",
    ").astype(int)\n",
    "\n",
    "# High heart rate criteria (HR > 150 bpm)\n",
    "final_df['red_pulse_high_flag'] = ((final_df['max_heart_rate'] > 150)).astype(int)\n",
    "# Low heart rate criteria (HR < 40 bpm)\n",
    "final_df['red_pulse_low_flag'] = ((final_df['min_heart_rate'] < 40) | final_df['min_heart_rate'].isna()).astype(int)\n",
    "\n",
    "# Yellow Respiratory Criteria\n",
    "final_df['yellow_resp_spo2_flag'] = ((final_df['min_spo2'] >= 90)| final_df['min_spo2'].isna()).astype(int)\n",
    "final_df['yellow_fio2_flag'] = ((final_df['min_fio2_set'] > 0.6)).astype(int)\n",
    "final_df['yellow_resp_rate_flag'] = ((final_df['max_respiratory_rate'] > 30)).astype(int)\n",
    "final_df['yellow_peep_flag'] = ((final_df['min_peep_set'] > 10)).astype(int)\n",
    "\n",
    "# Yellow Cardiovascular Criteria\n",
    "final_df['yellow_map_flag'] = (((final_df['avg_map'] >= 65) & (final_df['ne_calc_last'].between(0.1, 0.3)))).astype(int)\n",
    "final_df['yellow_pulse_flag'] = ((final_df['min_heart_rate'].between(120, 150))).astype(int)\n",
    "final_df['yellow_lactate_flag'] = ((final_df['lactate'] > 4)).astype(int)\n",
    "\n",
    "# Step 3: Implement Green Criteria\n",
    "final_df['green_resp_spo2_flag'] = ((final_df['min_spo2'] >= 90)| final_df['min_spo2'].isna()).astype(int)\n",
    "final_df['green_resp_rate_flag'] = ((final_df['max_respiratory_rate'] <= 30) | final_df['max_respiratory_rate'].isna()).astype(int)\n",
    "final_df['green_fio2_flag'] = ((final_df['min_fio2_set'] <= 0.6) | final_df['min_fio2_set'].isna()).astype(int)\n",
    "final_df['green_peep_flag'] = ((final_df['min_peep_set'] <= 10) | final_df['min_peep_set'].isna()).astype(int)\n",
    "\n",
    "# Green Cardiovascular Criteria\n",
    "final_df['green_map_flag'] = (((final_df['avg_map'] >= 65) & (final_df['ne_calc_last'] < 0.1)) | final_df['ne_calc_last'].isna()).astype(int)\n",
    "final_df['green_pulse_flag'] = ((final_df['min_heart_rate'] < 120) | final_df['min_heart_rate'].isna()).astype(int)\n",
    "final_df['green_lactate_flag'] = ((final_df['lactate'] < 4) | final_df['lactate'].isna()).astype(int)\n",
    "final_df['green_hr_flag'] = ((final_df['min_heart_rate'] > 40) | final_df['min_heart_rate'].isna()).astype(int)\n",
    "\n",
    "\n",
    "## Green subcomoponent flags\n",
    "final_df['green_resp_flag'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "# Green cardio flag: Combines MAP, SBP, lactate and Pulse criteria\n",
    "final_df['green_cardio_flag'] = (\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "final_df['any_red'] = (\n",
    "    (final_df['red_resp_spo2_flag'] |\n",
    "    final_df['red_map_flag'] |\n",
    "    final_df['red_high_support_flag'] |\n",
    "    final_df['red_hypertensive_flag'] |\n",
    "    final_df['red_pulse_high_flag'] |\n",
    "    final_df['red_pulse_low_flag']) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['no_red'] = (~(final_df['red_resp_spo2_flag'] |\n",
    "       final_df['red_map_flag'] |\n",
    "       final_df['red_high_support_flag'] |\n",
    "       final_df['red_hypertensive_flag'] |\n",
    "       final_df['red_pulse_high_flag'] |\n",
    "       final_df['red_pulse_low_flag']) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_yellow'] = (\n",
    "    (final_df['yellow_resp_spo2_flag'] |\n",
    "    final_df['yellow_fio2_flag'] |\n",
    "    final_df['yellow_resp_rate_flag'] |\n",
    "    final_df['yellow_peep_flag'] |\n",
    "    final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag']) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_green'] = (\n",
    "    (final_df['green_resp_spo2_flag'] |\n",
    "    final_df['green_resp_rate_flag'] |\n",
    "    final_df['green_fio2_flag'] |\n",
    "    final_df['green_peep_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag']) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green_all_hours'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green_no_red'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_green_no_red_yellow'] = (\n",
    "    final_df['green_resp_spo2_flag'] &\n",
    "    final_df['green_resp_rate_flag'] &\n",
    "    final_df['green_fio2_flag'] &\n",
    "    final_df['green_peep_flag'] &\n",
    "    final_df['green_map_flag'] &\n",
    "    final_df['green_pulse_flag'] &\n",
    "    final_df['green_lactate_flag'] &\n",
    "    final_df['green_hr_flag'] &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['any_yellow'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['all_yellow_no_red_green'] = (\n",
    "    final_df['yellow_resp_spo2_flag'] &\n",
    "    final_df['yellow_fio2_flag'] &\n",
    "    final_df['yellow_resp_rate_flag'] &\n",
    "    final_df['yellow_peep_flag'] &\n",
    "    final_df['yellow_map_flag'] &\n",
    "    final_df['yellow_pulse_flag'] &\n",
    "    final_df['yellow_lactate_flag'] &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['any_green'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_yellow_no_red_green'] = (\n",
    "    (final_df['yellow_resp_spo2_flag'] |\n",
    "    final_df['yellow_fio2_flag'] |\n",
    "    final_df['yellow_resp_rate_flag'] |\n",
    "    final_df['yellow_peep_flag'] |\n",
    "    final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag']) &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['any_green'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_yellow_or_green_no_red'] = (\n",
    "    (final_df['yellow_resp_spo2_flag'] |\n",
    "    final_df['yellow_fio2_flag'] |\n",
    "    final_df['yellow_resp_rate_flag'] |\n",
    "    final_df['yellow_peep_flag'] |\n",
    "    final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag'] |\n",
    "    final_df['green_resp_spo2_flag'] |\n",
    "    final_df['green_resp_rate_flag'] |\n",
    "    final_df['green_fio2_flag'] |\n",
    "    final_df['green_peep_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag']) &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['any_yellow_or_green_no_red_all_hours'] = (\n",
    "    (final_df['yellow_resp_spo2_flag'] |\n",
    "    final_df['yellow_fio2_flag'] |\n",
    "    final_df['yellow_resp_rate_flag'] |\n",
    "    final_df['yellow_peep_flag'] |\n",
    "    final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag'] |\n",
    "    final_df['green_resp_spo2_flag'] |\n",
    "    final_df['green_resp_rate_flag'] |\n",
    "    final_df['green_fio2_flag'] |\n",
    "    final_df['green_peep_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag']) &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_resp_flag'] = (\n",
    "    (final_df['yellow_resp_spo2_flag'] |\n",
    "    final_df['yellow_fio2_flag'] |\n",
    "    final_df['yellow_resp_rate_flag'] |\n",
    "    final_df['yellow_peep_flag'] |\n",
    "    final_df['green_resp_spo2_flag'] |\n",
    "    final_df['green_resp_rate_flag'] |\n",
    "    final_df['green_fio2_flag'] |\n",
    "    final_df['green_peep_flag']) &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_cardio_flag'] = (\n",
    "    (final_df['yellow_map_flag'] |\n",
    "    final_df['yellow_pulse_flag'] |\n",
    "    final_df['yellow_lactate_flag'] |\n",
    "    final_df['green_map_flag'] |\n",
    "    final_df['green_pulse_flag'] |\n",
    "    final_df['green_lactate_flag'] |\n",
    "    final_df['green_hr_flag']) &\n",
    "    (final_df['any_red'] == 0) &\n",
    "    (final_df['hourly_trach'] == 0) &\n",
    "    (final_df['paralytics_flag'] == 0) &\n",
    "    (final_df['recorded_hour'] >= 8) &\n",
    "    (final_df['recorded_hour'] < 17) &\n",
    "    (final_df['time_from_vent_adjusted'] != -1)\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_all_green'] = (\n",
    "    final_df['all_green_no_red'] &\n",
    "    (final_df['any_yellow'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "final_df['yellow_not_all_green'] = (\n",
    "    final_df['any_yellow_or_green_no_red'] &\n",
    "    (final_df['all_green_no_red'] == 0)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26646fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:10.508580Z",
     "iopub.status.busy": "2025-05-05T20:36:10.508425Z",
     "iopub.status.idle": "2025-05-05T20:36:10.543671Z",
     "shell.execute_reply": "2025-05-05T20:36:10.543264Z"
    },
    "papermill": {
     "duration": 0.043148,
     "end_time": "2025-05-05T20:36:10.544614",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.501466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print value counts for each flag\n",
    "print(final_df[['any_red', 'any_yellow', 'any_green' ,  'all_green',\n",
    "                'all_green_no_red', 'all_green_no_red_yellow', 'all_yellow_no_red_green', \n",
    "                'any_yellow_no_red_green','any_yellow_or_green_no_red','no_red' ,'yellow_all_green',\n",
    "                 'yellow_not_all_green' ]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5530d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:10.558381Z",
     "iopub.status.busy": "2025-05-05T20:36:10.558201Z",
     "iopub.status.idle": "2025-05-05T20:36:11.986352Z",
     "shell.execute_reply": "2025-05-05T20:36:11.985967Z"
    },
    "papermill": {
     "duration": 1.43621,
     "end_time": "2025-05-05T20:36:11.987403",
     "exception": false,
     "start_time": "2025-05-05T20:36:10.551193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df.to_parquet(f'../output/intermediate/final_df_w_criteria.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be41bf",
   "metadata": {
    "papermill": {
     "duration": 0.006368,
     "end_time": "2025-05-05T20:36:12.000188",
     "exception": false,
     "start_time": "2025-05-05T20:36:11.993820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc5a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:12.055155Z",
     "iopub.status.busy": "2025-05-05T20:36:12.054994Z",
     "iopub.status.idle": "2025-05-05T20:36:12.401969Z",
     "shell.execute_reply": "2025-05-05T20:36:12.401648Z"
    },
    "papermill": {
     "duration": 0.35474,
     "end_time": "2025-05-05T20:36:12.402856",
     "exception": false,
     "start_time": "2025-05-05T20:36:12.048116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create criteria_results df with one row per encounter showing if criteria were ever met\n",
    "criteria_block_results = final_df.groupby('encounter_block').agg({\n",
    "    'patel_flag': 'max',  # 1 if criteria ever met\n",
    "    'team_flag': 'max',\n",
    "    'any_yellow_or_green_no_red': 'max',\n",
    "    'all_green': 'max',\n",
    "    'all_green_no_red': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "final_df_blocks_merged = final_df_blocks.merge(criteria_block_results, on='encounter_block', how='left')\n",
    "\n",
    "#  aggregate the values from final_df at encounter_block level\n",
    "vaso_peep_fio2_stats = final_df.groupby('encounter_block').agg({\n",
    "    'ne_calc_last': 'max',  # If any value is > 0, the block received vasopressors\n",
    "    'max_peep_set': 'mean',  # Average of max PEEP in the block\n",
    "    'min_fio2_set': 'mean'   # Average of min FiO2 in the block\n",
    "}).reset_index()\n",
    "\n",
    "# Merge these stats with final_df_blocks\n",
    "all_encounters = final_df_blocks_merged.copy()\n",
    "all_encounters = pd.merge(all_encounters, vaso_peep_fio2_stats, on='encounter_block', how='left')\n",
    "\n",
    "# Create subsets and map race for each\n",
    "def map_race_column(df, race_column='race'):\n",
    "    race_mapping = {\n",
    "        'Black or African-American': 'Black',\n",
    "        'Black or African American': 'Black',\n",
    "        'White': 'White',\n",
    "        'Asian': 'Other',\n",
    "        'American Indian or Alaska Native': 'Other',\n",
    "        'Native Hawaiian or Other Pacific Islander': 'Other',\n",
    "        'Other': 'Other',\n",
    "        'Unknown': 'Other'\n",
    "    }\n",
    "    df['race_new'] = df[race_column].map(race_mapping).fillna('Missing')\n",
    "    return df\n",
    "\n",
    "# Map race and create subsets\n",
    "all_encounters = map_race_column(all_encounters, 'race_category')\n",
    "patel_subset = map_race_column(all_encounters[all_encounters['patel_flag'] == 1].copy(), 'race_category')\n",
    "team_subset = map_race_column(all_encounters[all_encounters['team_flag'] == 1].copy(), 'race_category')\n",
    "yellow_subset = map_race_column(all_encounters[all_encounters['any_yellow_or_green_no_red'] == 1].copy(), 'race_category')\n",
    "green_subset = map_race_column(all_encounters[all_encounters['all_green'] == 1].copy(), 'race_category')\n",
    "green_no_red_subset = map_race_column(all_encounters[all_encounters['all_green_no_red'] == 1].copy(), 'race_category')\n",
    "\n",
    "# Calculate vasopressor usage for each subset\n",
    "def calculate_vasopressor_stats(df):\n",
    "    # Count encounters with any vasopressor use (ne_calc_last > 0)\n",
    "    vaso_usage = df['ne_calc_last'].notna() & (df['ne_calc_last'] > 0)\n",
    "    n_vaso = vaso_usage.sum()\n",
    "    n_zero = (df['ne_calc_last'] == 0).sum()\n",
    "    n_missing = df['ne_calc_last'].isna().sum()\n",
    "    total = len(df)\n",
    "    return n_vaso, n_zero, n_missing, total\n",
    "\n",
    "# Calculate stats for each group\n",
    "vaso_stats = {\n",
    "    'All Encounters': calculate_vasopressor_stats(all_encounters),\n",
    "    'Patel Criteria': calculate_vasopressor_stats(patel_subset),\n",
    "    'TEAM Criteria': calculate_vasopressor_stats(team_subset),\n",
    "    'Yellow Criteria': calculate_vasopressor_stats(yellow_subset),\n",
    "    'Green Criteria': calculate_vasopressor_stats(green_subset),\n",
    "    'Green-No-Red Criteria': calculate_vasopressor_stats(green_no_red_subset)\n",
    "}\n",
    "\n",
    "# Define variables for the table\n",
    "categorical = ['sex_category', 'race_new', 'ethnicity_category', \n",
    "              'location_category', 'is_dead']\n",
    "\n",
    "continuous = ['age_at_admission', 'sofa_cv_97', 'sofa_coag', 'sofa_renal',\n",
    "             'sofa_liver', 'sofa_resp', 'sofa_cns', 'sofa_total',\n",
    "             'ne_calc_last', 'max_peep_set', 'min_fio2_set']\n",
    "\n",
    "# Create individual tables\n",
    "# All Encounters - This will be our template\n",
    "table_all = TableOne(all_encounters, \n",
    "                    columns=categorical + continuous,\n",
    "                    categorical=categorical,\n",
    "                    groupby=None,\n",
    "                    nonnormal=continuous,\n",
    "                    pval=False)\n",
    "df_all = table_all.tableone.reset_index()\n",
    "\n",
    "# Filter out the 'n' row from the template\n",
    "# df_all = df_all[~((df_all['level_0'] == 'n') & (df_all['level_1'].isna()))]\n",
    "\n",
    "# Get the last column and the index columns\n",
    "df_template = pd.DataFrame({\n",
    "    'Characteristics': df_all['level_0'],\n",
    "    'Category': df_all['level_1'],\n",
    "    'All Encounters': df_all[df_all.columns[-1]]\n",
    "})\n",
    "\n",
    "# Function to process each criteria subset\n",
    "def process_criteria_subset(subset_df, criteria_name, template):\n",
    "    table = TableOne(subset_df,\n",
    "                    columns=categorical + continuous,\n",
    "                    categorical=categorical,\n",
    "                    groupby=None,\n",
    "                    nonnormal=continuous,\n",
    "                    pval=False)\n",
    "    df = table.tableone.reset_index()\n",
    "    \n",
    "    # Filter out the 'n' row\n",
    "    df = df[~((df['level_0'] == 'n') & (df['level_1'].isna()))]\n",
    "    \n",
    "    # Create a DataFrame with the same structure as template\n",
    "    result = pd.DataFrame({\n",
    "        'Characteristics': df['level_0'],\n",
    "        'Category': df['level_1'],\n",
    "        criteria_name: df[df.columns[-1]]\n",
    "    })\n",
    "    \n",
    "    # Merge with template to ensure all categories are present\n",
    "    merged = pd.merge(template[['Characteristics', 'Category']], \n",
    "                     result,\n",
    "                     on=['Characteristics', 'Category'],\n",
    "                     how='left')\n",
    "    \n",
    "    return merged[criteria_name]\n",
    "\n",
    "# Process each criteria subset\n",
    "patel_col = process_criteria_subset(patel_subset, 'Patel Criteria', df_template)\n",
    "team_col = process_criteria_subset(team_subset, 'TEAM Criteria', df_template)\n",
    "yellow_col = process_criteria_subset(yellow_subset, 'Yellow Criteria', df_template)\n",
    "green_col = process_criteria_subset(green_subset, 'Green Criteria', df_template)\n",
    "green_no_red_col = process_criteria_subset(green_no_red_subset, 'Green-No-Red Criteria', df_template)\n",
    "\n",
    "# Combine all columns\n",
    "final_table = pd.concat([\n",
    "    df_template[['Characteristics', 'Category', 'All Encounters']],\n",
    "    patel_col,\n",
    "    team_col,\n",
    "    yellow_col,\n",
    "    green_col,\n",
    "    green_no_red_col\n",
    "], axis=1)\n",
    "\n",
    "# Clean up the table\n",
    "# Remove the 'Missing' category if it exists and has count of 0\n",
    "final_table = final_table[~((final_table['Category'] == 'Missing') & \n",
    "                          (final_table['All Encounters'].str.startswith('0')))]\n",
    "\n",
    "# Format mortality rows\n",
    "mortality_rows = final_table.loc[final_table['Characteristics'] == 'is_dead']\n",
    "for col in final_table.columns[2:]:  # Skip 'Characteristics' and 'Category'\n",
    "    if col == 'All Encounters':\n",
    "        total = len(all_encounters)\n",
    "        deaths = all_encounters['is_dead'].sum()\n",
    "    elif col == 'Patel Criteria':\n",
    "        total = len(patel_subset)\n",
    "        deaths = patel_subset['is_dead'].sum()\n",
    "    elif col == 'TEAM Criteria':\n",
    "        total = len(team_subset)\n",
    "        deaths = team_subset['is_dead'].sum()\n",
    "    elif col == 'Yellow Criteria':\n",
    "        total = len(yellow_subset)\n",
    "        deaths = yellow_subset['is_dead'].sum()\n",
    "    elif col == 'Green Criteria':\n",
    "        total = len(green_subset)\n",
    "        deaths = green_subset['is_dead'].sum()\n",
    "    else:  # Green No Red Criteria\n",
    "        total = len(green_no_red_subset)\n",
    "        deaths = green_no_red_subset['is_dead'].sum()\n",
    "    \n",
    "    percentage = (deaths / total * 100) if total > 0 else 0\n",
    "    mortality_rows.loc[mortality_rows['Category'] == '1', col] = f\"{deaths} ({percentage:.1f})\"\n",
    "\n",
    "# Replace the original mortality rows\n",
    "final_table.loc[final_table['Characteristics'] == 'is_dead'] = mortality_rows\n",
    "\n",
    "# # Clean up labels\n",
    "final_table.loc[final_table['Characteristics'] == 'is_dead', 'Characteristics'] = 'Mortality'\n",
    "# final_table.loc[final_table['Category'] == '1', 'Category'] = ''\n",
    "\n",
    "# Add vasopressor usage rows\n",
    "vaso_rows = []\n",
    "for status in ['Received Vasopressors', 'No Vasopressors', 'Missing Vasopressor Data']:\n",
    "    row_data = {'Characteristics': 'Vasopressor Status', 'Category': status}\n",
    "    for col in final_table.columns[2:]:  # Skip 'Characteristics' and 'Category'\n",
    "        if col in vaso_stats:\n",
    "            n_vaso, n_zero, n_missing, total = vaso_stats[col]\n",
    "            if status == 'Received Vasopressors':\n",
    "                value = n_vaso\n",
    "            elif status == 'No Vasopressors':\n",
    "                value = n_zero\n",
    "            else:  # Missing Vasopressor Data\n",
    "                value = n_missing\n",
    "            \n",
    "            percentage = (value / total * 100) if total > 0 else 0\n",
    "            row_data[col] = f\"{value} ({percentage:.1f})\"\n",
    "    vaso_rows.append(row_data)\n",
    "\n",
    "vaso_df = pd.DataFrame(vaso_rows)\n",
    "final_table = pd.concat([final_table, vaso_df], ignore_index=True)\n",
    "\n",
    "# Add n row at the top (only once)\n",
    "n_row = pd.DataFrame({\n",
    "    'Characteristics': ['n'],\n",
    "    'Category': [''],\n",
    "    'All Encounters': [str(len(all_encounters))],\n",
    "    'Patel Criteria': [str(len(patel_subset))],\n",
    "    'TEAM Criteria': [str(len(team_subset))],\n",
    "    'Yellow Criteria': [str(len(yellow_subset))],\n",
    "    'Green Criteria': [str(len(green_subset))],\n",
    "    'Green-No-Red Criteria': [str(len(green_no_red_subset))]\n",
    "})\n",
    "\n",
    "final_table = pd.concat([n_row, final_table]).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_table.to_csv('../output/final/table1_results.csv', index=False)\n",
    "\n",
    "print(\"Table 1 has been generated and saved to table1_results.csv\")\n",
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815456d",
   "metadata": {},
   "source": [
    "## TableOne - 72 hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tableone import TableOne\n",
    "\n",
    "# 1) restrict all the raw hourly rows to the first 72 hours\n",
    "final_df_72h = final_df.query(\"time_from_vent <= 72\").copy()\n",
    "\n",
    "# Create criteria_results df with one row per encounter showing if criteria were ever met\n",
    "criteria_block_results = final_df_72h.groupby('encounter_block').agg({\n",
    "    'patel_flag': 'max',  # 1 if criteria ever met\n",
    "    'team_flag': 'max',\n",
    "    'any_yellow_or_green_no_red': 'max',\n",
    "    'all_green': 'max',\n",
    "    'all_green_no_red': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "final_df_blocks_72h = final_df_blocks[\n",
    "    final_df_blocks['encounter_block'].isin(criteria_block_results['encounter_block'])\n",
    "].copy()\n",
    "\n",
    "final_df_blocks_72h = final_df_blocks_72h.merge(\n",
    "    criteria_block_results,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#  aggregate the values from final_df at encounter_block level\n",
    "vaso_peep_fio2_stats = final_df.groupby('encounter_block').agg({\n",
    "    'ne_calc_last': 'max',  # If any value is > 0, the block received vasopressors\n",
    "    'max_peep_set': 'mean',  # Average of max PEEP in the block\n",
    "    'min_fio2_set': 'mean'   # Average of min FiO2 in the block\n",
    "}).reset_index()\n",
    "\n",
    "# Merge these stats with final_df_blocks\n",
    "all_encounters = final_df_blocks_72h.merge(\n",
    "    vaso_peep_fio2_stats,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create subsets and map race for each\n",
    "def map_race_column(df, race_column='race'):\n",
    "    race_mapping = {\n",
    "        'Black or African-American': 'Black',\n",
    "        'Black or African American': 'Black',\n",
    "        'White': 'White',\n",
    "        'Asian': 'Other',\n",
    "        'American Indian or Alaska Native': 'Other',\n",
    "        'Native Hawaiian or Other Pacific Islander': 'Other',\n",
    "        'Other': 'Other',\n",
    "        'Unknown': 'Other'\n",
    "    }\n",
    "    df['race_new'] = df[race_column].map(race_mapping).fillna('Missing')\n",
    "    return df\n",
    "\n",
    "# Map race and create subsets\n",
    "all_encounters = map_race_column(all_encounters, 'race_category')\n",
    "patel_subset = map_race_column(all_encounters[all_encounters['patel_flag'] == 1].copy(), 'race_category')\n",
    "team_subset = map_race_column(all_encounters[all_encounters['team_flag'] == 1].copy(), 'race_category')\n",
    "yellow_subset = map_race_column(all_encounters[all_encounters['any_yellow_or_green_no_red'] == 1].copy(), 'race_category')\n",
    "green_subset = map_race_column(all_encounters[all_encounters['all_green'] == 1].copy(), 'race_category')\n",
    "green_no_red_subset = map_race_column(all_encounters[all_encounters['all_green_no_red'] == 1].copy(), 'race_category')\n",
    "\n",
    "# Calculate vasopressor usage for each subset\n",
    "def calculate_vasopressor_stats(df):\n",
    "    # Count encounters with any vasopressor use (ne_calc_last > 0)\n",
    "    vaso_usage = df['ne_calc_last'].notna() & (df['ne_calc_last'] > 0)\n",
    "    n_vaso = vaso_usage.sum()\n",
    "    n_zero = (df['ne_calc_last'] == 0).sum()\n",
    "    n_missing = df['ne_calc_last'].isna().sum()\n",
    "    total = len(df)\n",
    "    return n_vaso, n_zero, n_missing, total\n",
    "\n",
    "# Calculate stats for each group\n",
    "vaso_stats = {\n",
    "    'All Encounters': calculate_vasopressor_stats(all_encounters),\n",
    "    'Patel Criteria': calculate_vasopressor_stats(patel_subset),\n",
    "    'TEAM Criteria': calculate_vasopressor_stats(team_subset),\n",
    "    'Yellow Criteria': calculate_vasopressor_stats(yellow_subset),\n",
    "    'Green Criteria': calculate_vasopressor_stats(green_subset),\n",
    "    'Green-No-Red Criteria': calculate_vasopressor_stats(green_no_red_subset)\n",
    "}\n",
    "\n",
    "# Define variables for the table\n",
    "categorical = ['sex_category', 'race_new', 'ethnicity_category', \n",
    "              'location_category', 'is_dead']\n",
    "\n",
    "continuous = ['age_at_admission', 'sofa_cv_97', 'sofa_coag', 'sofa_renal',\n",
    "             'sofa_liver', 'sofa_resp', 'sofa_cns', 'sofa_total',\n",
    "             'ne_calc_last', 'max_peep_set', 'min_fio2_set']\n",
    "\n",
    "# Create individual tables\n",
    "# All Encounters - This will be our template\n",
    "table_all = TableOne(all_encounters, \n",
    "                    columns=categorical + continuous,\n",
    "                    categorical=categorical,\n",
    "                    groupby=None,\n",
    "                    nonnormal=continuous,\n",
    "                    pval=False)\n",
    "df_all = table_all.tableone.reset_index()\n",
    "\n",
    "# Filter out the 'n' row from the template\n",
    "# df_all = df_all[~((df_all['level_0'] == 'n') & (df_all['level_1'].isna()))]\n",
    "\n",
    "# Get the last column and the index columns\n",
    "df_template = pd.DataFrame({\n",
    "    'Characteristics': df_all['level_0'],\n",
    "    'Category': df_all['level_1'],\n",
    "    'All Encounters': df_all[df_all.columns[-1]]\n",
    "})\n",
    "\n",
    "# Function to process each criteria subset\n",
    "def process_criteria_subset(subset_df, criteria_name, template):\n",
    "    table = TableOne(subset_df,\n",
    "                    columns=categorical + continuous,\n",
    "                    categorical=categorical,\n",
    "                    groupby=None,\n",
    "                    nonnormal=continuous,\n",
    "                    pval=False)\n",
    "    df = table.tableone.reset_index()\n",
    "    \n",
    "    # Filter out the 'n' row\n",
    "    df = df[~((df['level_0'] == 'n') & (df['level_1'].isna()))]\n",
    "    \n",
    "    # Create a DataFrame with the same structure as template\n",
    "    result = pd.DataFrame({\n",
    "        'Characteristics': df['level_0'],\n",
    "        'Category': df['level_1'],\n",
    "        criteria_name: df[df.columns[-1]]\n",
    "    })\n",
    "    \n",
    "    # Merge with template to ensure all categories are present\n",
    "    merged = pd.merge(template[['Characteristics', 'Category']], \n",
    "                     result,\n",
    "                     on=['Characteristics', 'Category'],\n",
    "                     how='left')\n",
    "    \n",
    "    return merged[criteria_name]\n",
    "\n",
    "# Process each criteria subset\n",
    "patel_col = process_criteria_subset(patel_subset, 'Patel Criteria', df_template)\n",
    "team_col = process_criteria_subset(team_subset, 'TEAM Criteria', df_template)\n",
    "yellow_col = process_criteria_subset(yellow_subset, 'Yellow Criteria', df_template)\n",
    "green_col = process_criteria_subset(green_subset, 'Green Criteria', df_template)\n",
    "green_no_red_col = process_criteria_subset(green_no_red_subset, 'Green-No-Red Criteria', df_template)\n",
    "\n",
    "# Combine all columns\n",
    "final_table = pd.concat([\n",
    "    df_template[['Characteristics', 'Category', 'All Encounters']],\n",
    "    patel_col,\n",
    "    team_col,\n",
    "    yellow_col,\n",
    "    green_col,\n",
    "    green_no_red_col\n",
    "], axis=1)\n",
    "\n",
    "# Clean up the table\n",
    "# Remove the 'Missing' category if it exists and has count of 0\n",
    "final_table = final_table[~((final_table['Category'] == 'Missing') & \n",
    "                          (final_table['All Encounters'].str.startswith('0')))]\n",
    "\n",
    "# Format mortality rows\n",
    "mortality_rows = final_table.loc[final_table['Characteristics'] == 'is_dead']\n",
    "for col in final_table.columns[2:]:  # Skip 'Characteristics' and 'Category'\n",
    "    if col == 'All Encounters':\n",
    "        total = len(all_encounters)\n",
    "        deaths = all_encounters['is_dead'].sum()\n",
    "    elif col == 'Patel Criteria':\n",
    "        total = len(patel_subset)\n",
    "        deaths = patel_subset['is_dead'].sum()\n",
    "    elif col == 'TEAM Criteria':\n",
    "        total = len(team_subset)\n",
    "        deaths = team_subset['is_dead'].sum()\n",
    "    elif col == 'Yellow Criteria':\n",
    "        total = len(yellow_subset)\n",
    "        deaths = yellow_subset['is_dead'].sum()\n",
    "    elif col == 'Green Criteria':\n",
    "        total = len(green_subset)\n",
    "        deaths = green_subset['is_dead'].sum()\n",
    "    else:  # Green No Red Criteria\n",
    "        total = len(green_no_red_subset)\n",
    "        deaths = green_no_red_subset['is_dead'].sum()\n",
    "    \n",
    "    percentage = (deaths / total * 100) if total > 0 else 0\n",
    "    mortality_rows.loc[mortality_rows['Category'] == '1', col] = f\"{deaths} ({percentage:.1f})\"\n",
    "\n",
    "# Replace the original mortality rows\n",
    "final_table.loc[final_table['Characteristics'] == 'is_dead'] = mortality_rows\n",
    "\n",
    "# # Clean up labels\n",
    "final_table.loc[final_table['Characteristics'] == 'is_dead', 'Characteristics'] = 'Mortality'\n",
    "# final_table.loc[final_table['Category'] == '1', 'Category'] = ''\n",
    "\n",
    "# Add vasopressor usage rows\n",
    "vaso_rows = []\n",
    "for status in ['Received Vasopressors', 'No Vasopressors', 'Missing Vasopressor Data']:\n",
    "    row_data = {'Characteristics': 'Vasopressor Status', 'Category': status}\n",
    "    for col in final_table.columns[2:]:  # Skip 'Characteristics' and 'Category'\n",
    "        if col in vaso_stats:\n",
    "            n_vaso, n_zero, n_missing, total = vaso_stats[col]\n",
    "            if status == 'Received Vasopressors':\n",
    "                value = n_vaso\n",
    "            elif status == 'No Vasopressors':\n",
    "                value = n_zero\n",
    "            else:  # Missing Vasopressor Data\n",
    "                value = n_missing\n",
    "            \n",
    "            percentage = (value / total * 100) if total > 0 else 0\n",
    "            row_data[col] = f\"{value} ({percentage:.1f})\"\n",
    "    vaso_rows.append(row_data)\n",
    "\n",
    "vaso_df = pd.DataFrame(vaso_rows)\n",
    "final_table = pd.concat([final_table, vaso_df], ignore_index=True)\n",
    "\n",
    "# Add n row at the top (only once)\n",
    "n_row = pd.DataFrame({\n",
    "    'Characteristics': ['n'],\n",
    "    'Category': [''],\n",
    "    'All Encounters': [str(len(all_encounters))],\n",
    "    'Patel Criteria': [str(len(patel_subset))],\n",
    "    'TEAM Criteria': [str(len(team_subset))],\n",
    "    'Yellow Criteria': [str(len(yellow_subset))],\n",
    "    'Green Criteria': [str(len(green_subset))],\n",
    "    'Green-No-Red Criteria': [str(len(green_no_red_subset))]\n",
    "})\n",
    "\n",
    "final_table = pd.concat([n_row, final_table]).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_table.to_csv('../output/final/table1_resultss_72hrs.csv', index=False)\n",
    "\n",
    "print(\"Table 1 has been generated and saved to table1_results_72hrs.csv\")\n",
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce578b",
   "metadata": {
    "papermill": {
     "duration": 0.006866,
     "end_time": "2025-05-05T20:36:12.721557",
     "exception": false,
     "start_time": "2025-05-05T20:36:12.714691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Missingess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f1256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:12.736050Z",
     "iopub.status.busy": "2025-05-05T20:36:12.735862Z",
     "iopub.status.idle": "2025-05-05T20:36:12.740106Z",
     "shell.execute_reply": "2025-05-05T20:36:12.739676Z"
    },
    "papermill": {
     "duration": 0.012951,
     "end_time": "2025-05-05T20:36:12.741178",
     "exception": false,
     "start_time": "2025-05-05T20:36:12.728227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key_variables =['encounter_block','hospitalization_id', \n",
    "                'recorded_date'\t,'recorded_hour', 'time_from_vent',\n",
    "                'hourly_trach','paralytics_flag',]\n",
    "\n",
    "reqd_team_fields = ['hourly_trach','paralytics_flag',\n",
    "                    'lactate', 'max_heart_rate', 'ne_calc_last',\n",
    "                    'last_ne_dose_last_6_hours', 'min_fio2_set', 'max_peep_set', \n",
    "                    'max_resp_rate_obs', \"team_pulse_flag\", \"team_lactate_flag\", \"team_ne_flag\",\n",
    "                    \"team_fio2_flag\",  \"team_peep_flag\",    \"team_resp_rate_flag\"]\n",
    "\n",
    "reqd_yellow_fields =[\n",
    "    # Clinical Measurements\n",
    "    'min_spo2', 'min_map', 'max_map', 'ne_calc_last', 'max_sbp', \"avg_map\",\n",
    "    'max_heart_rate', 'min_heart_rate', 'min_fio2_set',\n",
    "    'max_resp_rate_obs', 'min_peep_set', 'lactate',\n",
    "    \n",
    "    # Red Flags\n",
    "    'red_resp_spo2_flag', 'red_map_flag', 'red_high_support_flag',\n",
    "    'red_hypertensive_flag', 'red_pulse_high_flag', 'red_pulse_low_flag',\n",
    "    'red_meds_flag',\n",
    "    \n",
    "    # Yellow Flags\n",
    "    'yellow_resp_spo2_flag', 'yellow_fio2_flag', 'yellow_resp_rate_flag',\n",
    "    'yellow_peep_flag', 'yellow_map_flag', 'yellow_pulse_flag',\n",
    "    'yellow_lactate_flag',\n",
    "    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    \n",
    "    # Composite Flags\n",
    "    'any_red', 'any_yellow', 'any_green', 'all_green',\n",
    "    'all_green_no_red', 'all_green_no_red_yellow',\n",
    "    'all_yellow_no_red_green', 'any_yellow_no_red_green',\n",
    "    'any_yellow_or_green_no_red', 'yellow_resp_flag',\n",
    "    'yellow_cardio_flag', 'yellow_all_green', 'yellow_not_all_green'\n",
    "]\n",
    "\n",
    "reqd_patel_fields = ['min_map', 'max_map','max_sbp', 'min_sbp',\"avg_map\",\n",
    "                   'min_heart_rate','max_heart_rate', 'min_respiratory_rate','min_spo2', \n",
    "                    'max_respiratory_rate','patel_map_flag','patel_sbp_flag',\n",
    "                    'patel_pulse_flag', 'patel_resp_rate_flag' , 'patel_spo2_flag', \n",
    "                    'patel_resp_flag', 'patel_cardio_flag' ]\n",
    "\n",
    "reqd_green_fields =[\n",
    "    # Clinical Measurements\n",
    "    'min_spo2', 'min_map', 'max_map', 'ne_calc_last', 'max_sbp',\"avg_map\",\n",
    "    'max_heart_rate', 'min_heart_rate', 'min_fio2_set',\n",
    "    'max_resp_rate_obs', 'min_peep_set', 'lactate',\n",
    "\n",
    "    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    \n",
    "    # Composite Flags\n",
    "     'all_green',\n",
    "    'all_green_no_red', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a9ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:12.755773Z",
     "iopub.status.busy": "2025-05-05T20:36:12.755569Z",
     "iopub.status.idle": "2025-05-05T20:36:20.444049Z",
     "shell.execute_reply": "2025-05-05T20:36:20.443737Z"
    },
    "papermill": {
     "duration": 7.696713,
     "end_time": "2025-05-05T20:36:20.444842",
     "exception": false,
     "start_time": "2025-05-05T20:36:12.748129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate percentage of missing values per encounter block\n",
    "def calculate_missing_percentage(df, variable_list, exclude_flags=True):\n",
    "    # Filter out flag variables if requested\n",
    "    if exclude_flags:\n",
    "        vars_to_check = [var for var in variable_list if 'flag' not in var.lower()]\n",
    "    else:\n",
    "        vars_to_check = variable_list\n",
    "        \n",
    "    # Remove key variables that are administrative\n",
    "    vars_to_check = [var for var in vars_to_check if var not in ['encounter_block', 'hospitalization_id', \n",
    "                                                                'recorded_dttm', 'recorded_date', 'recorded_hour', \n",
    "                                                                'time_from_vent', 'hourly_trach', 'paralytics_flag']]\n",
    "    \n",
    "    # Calculate percentage of blocks where variable was never measured\n",
    "    missing_pct = {}\n",
    "    total_blocks = df['encounter_block'].nunique()\n",
    "    \n",
    "    for var in vars_to_check:\n",
    "        blocks_never_measured = df.groupby('encounter_block')[var].apply(lambda x: x.isna().all()).sum()\n",
    "        missing_pct[var] = (blocks_never_measured / total_blocks) * 100\n",
    "        \n",
    "    return pd.Series(missing_pct).sort_values(ascending=False)\n",
    "\n",
    "# Calculate for each criteria set\n",
    "team_missing = calculate_missing_percentage(final_df, reqd_team_fields)\n",
    "yellow_missing = calculate_missing_percentage(final_df, reqd_yellow_fields)\n",
    "patel_missing = calculate_missing_percentage(final_df, reqd_patel_fields)\n",
    "green_missing = calculate_missing_percentage(final_df, reqd_green_fields)\n",
    "green_no_red_missing = calculate_missing_percentage(final_df, reqd_yellow_fields)\n",
    "\n",
    "# def plot_missing_data(missing_series, title):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     sns.barplot(x=missing_series.values, y=missing_series.index)\n",
    "#     plt.title(f\"Percentage of Blocks with Never Measured Variables - {title}\")\n",
    "#     plt.xlabel(\"Percentage of Blocks (%)\")\n",
    "#     plt.ylabel(\"Variables\")\n",
    "#     plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot for each criteria set\n",
    "# plot_missing_data(team_missing, \"TEAM Criteria\")\n",
    "# plot_missing_data(yellow_missing, \"Yellow Criteria\")\n",
    "# plot_missing_data(patel_missing, \"Patel Criteria\")\n",
    "# plot_missing_data(green_missing, \"Patel Criteria\")\n",
    "\n",
    "# Print tabular summaries\n",
    "print(\"\\nTEAM Criteria Missing Data Summary:\")\n",
    "print(team_missing.round(2))\n",
    "print(\"\\nYellow Criteria Missing Data Summary:\")\n",
    "print(yellow_missing.round(2))\n",
    "print(\"\\nPatel Criteria Missing Data Summary:\")\n",
    "print(patel_missing.round(2))\n",
    "print(\"\\nGreen No Red Criteria Missing Data Summary:\")\n",
    "print(green_no_red_missing.round(2))\n",
    "\n",
    "team_missing.to_csv('../output/final/team_missing_data.csv')\n",
    "yellow_missing.to_csv('../output/final/yellow_missing_data.csv')\n",
    "patel_missing.to_csv('../output/final/patel_missing_data.csv')\n",
    "green_missing.to_csv('../output/final/green_missing_data.csv')\n",
    "green_no_red_missing.to_csv('../output/final/green_no_red_missing_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342498d1",
   "metadata": {
    "papermill": {
     "duration": 0.008376,
     "end_time": "2025-05-05T20:36:20.461061",
     "exception": false,
     "start_time": "2025-05-05T20:36:20.452685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Competing Risk Analysis Setup\n",
    "\n",
    "Create a dataframe for each criteria with the following columns \n",
    "\n",
    "1. encounter_block: identify the patient encounter\n",
    "2. time_eligibility: earliest eligibility time from first intubation episode per encounter block\n",
    "3. time_death: time from ventilation start to death, if applicable. Missing if not dead\n",
    "4. time_discharge_alive: time from ventilation start to discharge. If not dead, assumed discharged and the last recorded vital time is discharge time.\n",
    "5. t_event: earliest of the above three times\n",
    "6. outcome: 1(eligibility), 2(death), 3(discharge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f477c1",
   "metadata": {
    "papermill": {
     "duration": 0.008038,
     "end_time": "2025-05-05T20:36:20.476880",
     "exception": false,
     "start_time": "2025-05-05T20:36:20.468842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Competing risk updated (4/14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fa796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:20.493080Z",
     "iopub.status.busy": "2025-05-05T20:36:20.492901Z",
     "iopub.status.idle": "2025-05-05T20:36:20.499638Z",
     "shell.execute_reply": "2025-05-05T20:36:20.499369Z"
    },
    "papermill": {
     "duration": 0.016036,
     "end_time": "2025-05-05T20:36:20.500412",
     "exception": false,
     "start_time": "2025-05-05T20:36:20.484376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Helper: build block‑level data set for competing‑risk analysis\n",
    "##############################################################################\n",
    "def create_competing_risk_dataset(\n",
    "    criteria_df: pd.DataFrame,\n",
    "    all_ids_w_outcome: pd.DataFrame,\n",
    "    flag_col: str = \"patel_flag\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One row per encounter_block with\n",
    "      time_eligibility        - first hour where <flag_col> == 1\n",
    "      time_death              - hours from vent start to death   (NaN if alive)\n",
    "      time_discharge_alive    - hours from vent start to discharge (NaN if died)\n",
    "      t_event                 - min of the three times\n",
    "      outcome                 - 1(eligible)/2(death)/3(discharge)\n",
    "\n",
    "    Assumptions\n",
    "    -----------\n",
    "    • time_from_vent (in hours) is already *after* the 4hour cool-off.  \n",
    "    • all_ids_w_outcome has one row per encounter_block.\n",
    "    \"\"\"\n",
    "\n",
    "    ###################################################################\n",
    "    # 0) Basic column checks\n",
    "    ###################################################################\n",
    "    needed_cols = [\n",
    "        \"encounter_block\",\n",
    "        \"time_from_vent\",          # raw hours since intubation (already cooled‑off)\n",
    "        \"recorded_date\",          \n",
    "        \"recorded_hour\",\n",
    "        flag_col\n",
    "    ]\n",
    "    missing = [c for c in needed_cols if c not in criteria_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"criteria_df is missing columns: {missing}\")\n",
    "\n",
    "    ###################################################################\n",
    "    # 1) FIRST ELIGIBILITY TIME  (earliest hour where flag==1)\n",
    "    ###################################################################\n",
    "    first_elig = (\n",
    "        criteria_df\n",
    "        .loc[criteria_df[flag_col] == 1, [\"encounter_block\", \"time_from_vent\"]]\n",
    "        .groupby(\"encounter_block\", as_index=False)\n",
    "        .min()\n",
    "        .rename(columns={\"time_from_vent\": \"time_eligibility\"})\n",
    "    )\n",
    "\n",
    "    ###################################################################\n",
    "    # 2) BLOCK‑LEVEL death / discharge times\n",
    "    ###################################################################\n",
    "    block_cols = [\n",
    "        \"encounter_block\",\n",
    "        \"block_vent_start_dttm\",\n",
    "        \"final_outcome_dttm\",\n",
    "        \"is_dead\"\n",
    "    ]\n",
    "    block_level = (\n",
    "        all_ids_w_outcome\n",
    "        .loc[all_ids_w_outcome[\"encounter_block\"].isin(criteria_df[\"encounter_block\"]),\n",
    "             block_cols]\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # convert to datetime once\n",
    "    block_level[\"block_vent_start_dttm\"] = pd.to_datetime(\n",
    "        block_level[\"block_vent_start_dttm\"], errors=\"coerce\"\n",
    "    )\n",
    "    block_level[\"final_outcome_dttm\"] = pd.to_datetime(\n",
    "        block_level[\"final_outcome_dttm\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # hours from vent start to the *final* outcome\n",
    "    hrs_from_vent = (\n",
    "        (block_level[\"final_outcome_dttm\"] - block_level[\"block_vent_start_dttm\"])\n",
    "        .dt.total_seconds() / 3600\n",
    "    )\n",
    "\n",
    "    block_level[\"time_death\"]            = np.where(\n",
    "        block_level[\"is_dead\"] == 1, hrs_from_vent, np.nan\n",
    "    )\n",
    "    block_level[\"time_discharge_alive\"]  = np.where(\n",
    "        block_level[\"is_dead\"] == 0, hrs_from_vent, np.nan\n",
    "    )\n",
    "\n",
    "    ###################################################################\n",
    "    # 3) MERGE and decide which event happened first\n",
    "    ###################################################################\n",
    "    final_df = (\n",
    "        block_level[[\"encounter_block\", \"time_death\", \"time_discharge_alive\"]]\n",
    "        .merge(first_elig, on=\"encounter_block\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    # earliest non‑NaN time\n",
    "    final_df[\"t_event\"] = final_df[[\"time_eligibility\",\n",
    "                                    \"time_death\",\n",
    "                                    \"time_discharge_alive\"]].min(axis=1, skipna=True)\n",
    "\n",
    "    # outcome code\n",
    "    def pick_outcome(r):\n",
    "        if np.isfinite(r[\"time_eligibility\"]) and r[\"t_event\"] == r[\"time_eligibility\"]:\n",
    "            return 1\n",
    "        if np.isfinite(r[\"time_death\"])       and r[\"t_event\"] == r[\"time_death\"]:\n",
    "            return 2\n",
    "        return 3   # discharge must be earliest\n",
    "\n",
    "    final_df[\"outcome\"] = final_df.apply(pick_outcome, axis=1)\n",
    "\n",
    "    return final_df[\n",
    "        [\"encounter_block\",\n",
    "         \"time_eligibility\",\n",
    "         \"time_death\",\n",
    "         \"time_discharge_alive\",\n",
    "         \"t_event\",\n",
    "         \"outcome\"]\n",
    "    ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f530310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:20.515930Z",
     "iopub.status.busy": "2025-05-05T20:36:20.515810Z",
     "iopub.status.idle": "2025-05-05T20:36:22.480919Z",
     "shell.execute_reply": "2025-05-05T20:36:22.480514Z"
    },
    "papermill": {
     "duration": 1.974011,
     "end_time": "2025-05-05T20:36:22.482034",
     "exception": false,
     "start_time": "2025-05-05T20:36:20.508023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "        final_df,\n",
    "        all_ids_w_outcome[['encounter_block',\n",
    "       'block_vent_start_dttm', 'block_vent_end_dttm',\n",
    "       'block_first_vital_dttm', 'block_last_vital_dttm', 'discharge_dttm',\n",
    "       'discharge_category', 'death_dttm', 'final_outcome_dttm', 'is_dead']],\n",
    "        on=  'encounter_block',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "df_merged_team   = df_merged.copy()\n",
    "df_merged_yellow = df_merged.copy()\n",
    "df_merged_patel  = df_merged.copy()\n",
    "df_merged_green = df_merged.copy()\n",
    "df_merged_green_no_red = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8716aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:22.499062Z",
     "iopub.status.busy": "2025-05-05T20:36:22.498925Z",
     "iopub.status.idle": "2025-05-05T20:36:22.811199Z",
     "shell.execute_reply": "2025-05-05T20:36:22.810865Z"
    },
    "papermill": {
     "duration": 0.32192,
     "end_time": "2025-05-05T20:36:22.812260",
     "exception": false,
     "start_time": "2025-05-05T20:36:22.490340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_patel_competing = create_competing_risk_dataset(\n",
    "    criteria_df        = df_merged_patel,\n",
    "    all_ids_w_outcome  = all_ids_w_outcome,\n",
    "    flag_col           = \"patel_flag\"\n",
    ")\n",
    "df_patel_competing.to_parquet(\"../output/intermediate/competing_risk_patel_final.parquet\")\n",
    "\n",
    "df_team_competing = create_competing_risk_dataset(\n",
    "    criteria_df        = df_merged_team,\n",
    "    all_ids_w_outcome  = all_ids_w_outcome,\n",
    "    flag_col           = \"team_flag\"\n",
    ")\n",
    "df_team_competing.to_parquet(\"../output/intermediate/competing_risk_team_final.parquet\")\n",
    "\n",
    "df_yellow_competing = create_competing_risk_dataset(\n",
    "    criteria_df        = df_merged_yellow,\n",
    "    all_ids_w_outcome  = all_ids_w_outcome,\n",
    "    flag_col           = \"any_yellow_or_green_no_red\"\n",
    ")\n",
    "df_yellow_competing.to_parquet(\"../output/intermediate/competing_risk_yellow_final.parquet\")\n",
    "\n",
    "df_green_competing = create_competing_risk_dataset(\n",
    "    criteria_df        = df_merged_green,\n",
    "    all_ids_w_outcome  = all_ids_w_outcome,\n",
    "    flag_col           = \"all_green\"\n",
    ")\n",
    "df_green_competing.to_parquet(\"../output/intermediate/competing_risk_green_final.parquet\")\n",
    "\n",
    "df_green_no_red_competing = create_competing_risk_dataset(\n",
    "    criteria_df        = df_merged_green_no_red,\n",
    "    all_ids_w_outcome  = all_ids_w_outcome,\n",
    "    flag_col           = \"all_green_no_red\"\n",
    ")\n",
    "df_green_no_red_competing.to_parquet(\"../output/intermediate/competing_risk_green_no_red_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c2f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:22.829640Z",
     "iopub.status.busy": "2025-05-05T20:36:22.829468Z",
     "iopub.status.idle": "2025-05-05T20:36:23.629326Z",
     "shell.execute_reply": "2025-05-05T20:36:23.629053Z"
    },
    "papermill": {
     "duration": 0.809844,
     "end_time": "2025-05-05T20:36:23.630135",
     "exception": false,
     "start_time": "2025-05-05T20:36:22.820291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import from_indicators, UpSet\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import from_indicators, UpSet\n",
    "\n",
    "def analyse_discharge_without_elig(competing_df, flag_prefix, title):\n",
    "    # ── prepare output directory ──\n",
    "    out_dir = \"../output/final/graphs\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # ── 1a) select blocks that failed entirely ──\n",
    "    no_elig_blocks = competing_df.loc[\n",
    "        competing_df[\"outcome\"] == 3, \"encounter_block\"\n",
    "    ].unique()\n",
    "    df_fail = final_df[final_df[\"encounter_block\"].isin(no_elig_blocks)]\n",
    "\n",
    "    # ── 1b) pick sub-criteria columns ──\n",
    "    crit_cols = [\n",
    "        c for c in df_fail.columns\n",
    "        if c.startswith(flag_prefix) and c.endswith(\"_flag\")\n",
    "           and c not in (f\"{flag_prefix}flag\", f\"{flag_prefix}cardio_flag\", f\"{flag_prefix}resp_flag\")\n",
    "    ]\n",
    "\n",
    "    # ── 1c) for each block, did it ever FAIL? ──\n",
    "    ever_fail = (df_fail[crit_cols] == 0).groupby(df_fail[\"encounter_block\"]).max()\n",
    "\n",
    "    # ── 2) BAR PLOT & CSV ──\n",
    "    freq = ever_fail.mean().sort_values(ascending=True)\n",
    "    # save raw data\n",
    "    freq.to_csv(\n",
    "        os.path.join(out_dir, f\"{title}_eligibility_failures_freq.csv\"),\n",
    "        header=[\"prop_blocks_failed\"]\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.barh(freq.index.str.replace(flag_prefix, \"\"), freq.values, color=\"#4c72b0\")\n",
    "    plt.xlabel(\"Proportion of encounter-blocks where criterion ever failed\")\n",
    "    plt.title(f\"{title}: which sub-criteria blocked eligibility?\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"{title}_eligibility_failures.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3) UPSET PLOT & CSV\n",
    "    # ----------------------------------------------------------------------\n",
    "    upset_data = from_indicators(ever_fail.columns, ever_fail)\n",
    "\n",
    "    # Manually build a DataFrame of each combination + its count\n",
    "    # ------------------------------------------------------------\n",
    "    #  a) pull out the indicator combinations as a DataFrame\n",
    "    combos = pd.DataFrame(list(upset_data.index), columns=upset_data.index.names)\n",
    "\n",
    "    #  b) pull out the counts as a 1D array\n",
    "    if isinstance(upset_data, pd.Series):\n",
    "        counts = upset_data.values\n",
    "    else:\n",
    "        # if it's a DataFrame, assume the last column is the count\n",
    "        counts = upset_data.iloc[:, -1].values\n",
    "\n",
    "    #  c) assemble\n",
    "    upset_df = combos.copy()\n",
    "    upset_df[\"count\"] = counts\n",
    "\n",
    "    # save to CSV\n",
    "    # upset_df.to_csv(\n",
    "    #     os.path.join(out_dir, f\"{title}_eligibility_failures_upset_data.csv\"),\n",
    "    #     index=False\n",
    "    # )\n",
    "\n",
    "    # now plot\n",
    "    UpSet(\n",
    "        upset_data,\n",
    "        show_counts=True,\n",
    "        sort_by=\"cardinality\",\n",
    "        intersection_plot_elements=15,\n",
    "        element_size=None\n",
    "    ).plot()\n",
    "    plt.suptitle(f\"{title}: top combinations of failed sub-criteria\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(out_dir, f\"{title}_eligibility_failures_upset.png\"),\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    return freq.to_frame(\"prop_blocks_failed\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2.  Run for each criterion\n",
    "# ---------------------------------------------------------------------------\n",
    "team_summary   = analyse_discharge_without_elig(df_team_competing,\n",
    "                                               flag_prefix=\"team_\",\n",
    "                                               title=\"TEAM\")\n",
    "\n",
    "patel_summary  = analyse_discharge_without_elig(df_patel_competing,\n",
    "                                               flag_prefix=\"patel_\",\n",
    "                                               title=\"Patel\")\n",
    "\n",
    "yellow_summary = analyse_discharge_without_elig(df_yellow_competing,\n",
    "                                               flag_prefix=\"yellow_\",\n",
    "                                               title=\"Yellow\")\n",
    "\n",
    "green_summary = analyse_discharge_without_elig(df_green_competing,\n",
    "                                               flag_prefix=\"green_\",\n",
    "                                               title=\"Green\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3.  Example: compare the three summaries side‑by‑side\n",
    "# ---------------------------------------------------------------------------\n",
    "compare = (team_summary.rename(columns={\"prop_blocks_failed\": \"TEAM\"})\n",
    "           .join(patel_summary.rename(columns={\"prop_blocks_failed\": \"Patel\"}), how=\"outer\")\n",
    "           .join(yellow_summary.rename(columns={\"prop_blocks_failed\": \"Yellow\"}), how=\"outer\")\n",
    "           .join(green_summary.rename(columns={\"prop_blocks_failed\": \"Green\"}), how=\"outer\")\n",
    "           .fillna(0)\n",
    "           .sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65244691",
   "metadata": {},
   "source": [
    "### Discharge alive without eligibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d7932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:23.650225Z",
     "iopub.status.busy": "2025-05-05T20:36:23.650045Z",
     "iopub.status.idle": "2025-05-05T20:36:23.663568Z",
     "shell.execute_reply": "2025-05-05T20:36:23.663256Z"
    },
    "papermill": {
     "duration": 0.024539,
     "end_time": "2025-05-05T20:36:23.664408",
     "exception": false,
     "start_time": "2025-05-05T20:36:23.639869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_team_fields = ['encounter_block', 'recorded_date'\t,'recorded_hour',\n",
    "                    'time_from_vent','hourly_trach','paralytics_flag',\n",
    "                    'lactate', 'max_heart_rate', 'ne_calc_max','ne_calc_last','last_ne_dose_last_6_hours', 'min_fio2_set', 'max_peep_set', \n",
    "                    'max_resp_rate_obs', \"team_pulse_flag\", \"team_lactate_flag\", \"team_ne_flag\",\n",
    "                    \"team_fio2_flag\",  \"team_peep_flag\",    \"team_resp_rate_flag\", \"team_flag\"]\n",
    "\n",
    "\n",
    "no_elig_blocks_team = df_team_competing.loc[df_team_competing[\"outcome\"] == 3,\n",
    "                                      \"encounter_block\"].unique()\n",
    "df_fail_team = final_df[final_df[\"encounter_block\"].isin(no_elig_blocks_team)]\n",
    "df_fail_team_filtered = df_fail_team[reqd_team_fields].copy()\n",
    "df_fail_team_filtered = df_fail_team_filtered.merge(all_ids_w_outcome[['discharge_category', 'encounter_block']], on='encounter_block', how='inner')\n",
    "\n",
    "failure_discharge_cats_team = df_fail_team_filtered.groupby('discharge_category')['encounter_block'].nunique().sort_values(ascending=False)\n",
    "#write to csv\n",
    "failure_discharge_cats_team.to_csv('../output/final/failure_discharge_cats_team.csv')\n",
    "failure_discharge_cats_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709404c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:23.684491Z",
     "iopub.status.busy": "2025-05-05T20:36:23.684290Z",
     "iopub.status.idle": "2025-05-05T20:36:23.696408Z",
     "shell.execute_reply": "2025-05-05T20:36:23.696145Z"
    },
    "papermill": {
     "duration": 0.023156,
     "end_time": "2025-05-05T20:36:23.697174",
     "exception": false,
     "start_time": "2025-05-05T20:36:23.674018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_patel_fields = ['encounter_block','recorded_date'\t,'recorded_hour',\n",
    "                    'time_from_vent', 'hourly_trach','paralytics_flag','min_spo2',\n",
    "                    'min_map', 'max_map','max_sbp', 'min_sbp','avg_map',    \n",
    "                   'min_heart_rate','max_heart_rate', 'min_respiratory_rate','min_spo2', \n",
    "                    'max_respiratory_rate','patel_map_flag','patel_sbp_flag','patel_pulse_flag', \n",
    "                    'patel_resp_rate_flag' , 'patel_spo2_flag', 'patel_resp_flag', 'patel_cardio_flag', 'patel_flag' ]\n",
    "no_elig_blocks_patel = df_patel_competing.loc[df_patel_competing[\"outcome\"] == 3,\n",
    "                                      \"encounter_block\"].unique()\n",
    "df_fail_patel = final_df[final_df[\"encounter_block\"].isin(no_elig_blocks_patel)]\n",
    "df_fail_patel_filtered = df_fail_patel[reqd_patel_fields].copy()\n",
    "df_fail_patel_filtered = df_fail_patel_filtered.merge(all_ids_w_outcome[['discharge_category', 'encounter_block']], \n",
    "                                                    on='encounter_block', how='inner')\n",
    "failure_discharge_cats_patel = df_fail_patel_filtered.groupby('discharge_category')['encounter_block'].nunique().sort_values(ascending=False)\n",
    "failure_discharge_cats_patel.to_csv('../output/final/failure_discharge_cats_patel.csv')\n",
    "failure_discharge_cats_patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ad404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:23.717169Z",
     "iopub.status.busy": "2025-05-05T20:36:23.717045Z",
     "iopub.status.idle": "2025-05-05T20:36:23.731308Z",
     "shell.execute_reply": "2025-05-05T20:36:23.731051Z"
    },
    "papermill": {
     "duration": 0.025189,
     "end_time": "2025-05-05T20:36:23.732081",
     "exception": false,
     "start_time": "2025-05-05T20:36:23.706892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_yellow_fields =[\n",
    "    'encounter_block','recorded_date'\t,'recorded_hour',\n",
    "    'time_from_vent', 'hourly_trach','paralytics_flag',\n",
    "    # Clinical Measurements\n",
    "    'min_spo2', 'min_map', 'max_map', 'ne_calc_max', 'max_sbp', 'avg_map',\n",
    "    'max_heart_rate', 'min_heart_rate', 'min_fio2_set',\n",
    "    'max_resp_rate_obs', 'min_peep_set', 'lactate',\n",
    "    \n",
    "    # Administrative/Timing\n",
    "    'hourly_trach', 'paralytics_flag', 'recorded_hour',\n",
    "    'time_from_vent_adjusted', 'red_meds_flag',\n",
    "    # Red Flags\n",
    "    'red_resp_spo2_flag', 'red_map_flag', 'red_high_support_flag',\n",
    "    'red_hypertensive_flag', 'red_pulse_high_flag', 'red_pulse_low_flag',\n",
    "    \n",
    "    # Yellow Flags\n",
    "    'yellow_resp_spo2_flag', 'yellow_fio2_flag', 'yellow_resp_rate_flag',\n",
    "    'yellow_peep_flag', 'yellow_map_flag', 'yellow_pulse_flag',\n",
    "    'yellow_lactate_flag',\n",
    "    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    \n",
    "    # Composite Flags\n",
    "    'any_red', 'any_yellow', 'any_green', 'all_green',\n",
    "    'all_green_no_red', 'all_green_no_red_yellow',\n",
    "    'all_yellow_no_red_green', 'any_yellow_no_red_green',\n",
    "    'any_yellow_or_green_no_red', 'yellow_resp_flag',\n",
    "    'yellow_cardio_flag', 'yellow_all_green', 'yellow_not_all_green'\n",
    "]\n",
    "no_elig_blocks_yellow = df_yellow_competing.loc[df_yellow_competing[\"outcome\"] == 3,\n",
    "                                      \"encounter_block\"].unique()\n",
    "df_fail_yellow = final_df[final_df[\"encounter_block\"].isin(no_elig_blocks_yellow)]\n",
    "df_fail_yellow_filtered = df_fail_yellow[reqd_yellow_fields].copy()\n",
    "df_fail_yellow_filtered = df_fail_yellow_filtered.merge(all_ids_w_outcome[['discharge_category', 'encounter_block']], \n",
    "                                                    on='encounter_block', how='inner')\n",
    "failure_discharge_cats_yellow = df_fail_yellow_filtered.groupby('discharge_category')['encounter_block'].nunique().sort_values(ascending=False)\n",
    "failure_discharge_cats_yellow.to_csv('../output/final/failure_discharge_cats_yellow.csv')\n",
    "failure_discharge_cats_yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce594997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:23.771987Z",
     "iopub.status.busy": "2025-05-05T20:36:23.771792Z",
     "iopub.status.idle": "2025-05-05T20:36:23.801906Z",
     "shell.execute_reply": "2025-05-05T20:36:23.801551Z"
    },
    "papermill": {
     "duration": 0.041979,
     "end_time": "2025-05-05T20:36:23.802779",
     "exception": false,
     "start_time": "2025-05-05T20:36:23.760800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_green_fields =[\n",
    "    'encounter_block','recorded_date'\t,'recorded_hour',\n",
    "    'time_from_vent', 'hourly_trach','paralytics_flag',\n",
    "    # Clinical Measurements\n",
    "    'min_spo2', 'min_map', 'max_map', 'ne_calc_max', 'max_sbp',\n",
    "    'max_heart_rate', 'min_heart_rate', 'min_fio2_set','avg_map',\n",
    "    'max_resp_rate_obs', 'min_peep_set', 'lactate',\n",
    "    \n",
    "    # Administrative/Timing\n",
    "    'hourly_trach', 'paralytics_flag', 'recorded_hour',\n",
    "    'time_from_vent_adjusted', 'red_meds_flag',\n",
    "    # Red Flags\n",
    "    'red_resp_spo2_flag', 'red_map_flag', 'red_high_support_flag',\n",
    "    'red_hypertensive_flag', 'red_pulse_high_flag', 'red_pulse_low_flag',\n",
    "    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    'all_green',\n",
    "    'all_green_no_red', \n",
    "]\n",
    "no_elig_blocks_green = df_green_competing.loc[df_green_competing[\"outcome\"] == 3,\n",
    "                                      \"encounter_block\"].unique()\n",
    "df_fail_green = final_df[final_df[\"encounter_block\"].isin(no_elig_blocks_green)]\n",
    "df_fail_green_filtered = df_fail_green[reqd_green_fields].copy()\n",
    "df_fail_green_filtered = df_fail_green_filtered.merge(all_ids_w_outcome[['discharge_category', 'encounter_block']], \n",
    "                                                    on='encounter_block', how='inner')\n",
    "failure_discharge_cats_green = df_fail_green_filtered.groupby('discharge_category')['encounter_block'].nunique().sort_values(ascending=False)\n",
    "failure_discharge_cats_green.to_csv('../output/final/failure_discharge_cats_green.csv')\n",
    "failure_discharge_cats_green"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843668d",
   "metadata": {
    "papermill": {
     "duration": 0.010201,
     "end_time": "2025-05-05T20:36:56.517925",
     "exception": false,
     "start_time": "2025-05-05T20:36:56.507724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb7142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:56.538761Z",
     "iopub.status.busy": "2025-05-05T20:36:56.538596Z",
     "iopub.status.idle": "2025-05-05T20:36:56.600120Z",
     "shell.execute_reply": "2025-05-05T20:36:56.599793Z"
    },
    "papermill": {
     "duration": 0.073623,
     "end_time": "2025-05-05T20:36:56.601065",
     "exception": false,
     "start_time": "2025-05-05T20:36:56.527442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_death_without_eligibility(df, criteria_name):\n",
    "    # Total number of blocks\n",
    "    total_blocks = len(df)\n",
    "    \n",
    "    # Blocks that died without eligibility (outcome=2)\n",
    "    died_without_elig = df[df['outcome'] == 2].shape[0]\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percent = (died_without_elig / total_blocks) * 100\n",
    "    \n",
    "    return {\n",
    "        'criteria': criteria_name,\n",
    "        'total_blocks': total_blocks,\n",
    "        'died_without_eligibility': died_without_elig,\n",
    "        'percentage': percent\n",
    "    }\n",
    "\n",
    "# Analyze each dataset\n",
    "results = [\n",
    "    analyze_death_without_eligibility(df_team_competing, 'TEAM'),\n",
    "    analyze_death_without_eligibility(df_yellow_competing, 'Yellow'),\n",
    "    analyze_death_without_eligibility(df_patel_competing, 'Patel'),\n",
    "    analyze_death_without_eligibility(df_green_competing, 'Green'),\n",
    "    analyze_death_without_eligibility(df_green_no_red_competing, 'Green No Red')\n",
    "]\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create grouped bar plot\n",
    "x = range(len(results_df['criteria']))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars\n",
    "bars = plt.bar(x, results_df['percentage'], width, label='Percentage')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Percentage of Blocks that Died Without Becoming Eligible by Criteria', pad=20)\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(x, results_df['criteria'])\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}%\\n({results_df[\"died_without_eligibility\"][i]:,}/{results_df[\"total_blocks\"][i]:,})',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print detailed summary\n",
    "print(\"\\nDetailed Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for result in results:\n",
    "    print(f\"\\n{result['criteria']} Criteria:\")\n",
    "    print(f\"Total blocks: {result['total_blocks']:,}\")\n",
    "    print(f\"Died without eligibility: {result['died_without_eligibility']:,}\")\n",
    "    print(f\"Percentage: {result['percentage']:.1f}%\")\n",
    "\n",
    "pd.DataFrame(results).to_csv('../output/final/death_without_eligibility_summary.csv', index=False)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beaef25",
   "metadata": {
    "papermill": {
     "duration": 0.010272,
     "end_time": "2025-05-05T20:36:56.647037",
     "exception": false,
     "start_time": "2025-05-05T20:36:56.636765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final figures and tables\n",
    "\n",
    "1. Figure 1: Percentage of encounter satisfying Patel, TEAM, and any yellow or GREEN criteria\n",
    "2. Figure 2: Percentage of business hours each encounter was eligible for different criteria\n",
    "3. Figure 3: Percentage of business hours not eligible for each criteria broken down by subcomponent failure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2179f22",
   "metadata": {},
   "source": [
    "### Aggregates - 72 hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ── flag dictionaries ------------------------------------------------\n",
    "CRITS_ALL = {\n",
    "    'Patel' : 'patel_flag_all_hours',\n",
    "    'TEAM'  : 'team_flag_all_hours',\n",
    "    'Yellow': 'any_yellow_or_green_no_red_all_hours',\n",
    "    'Green' : 'all_green_all_hours',\n",
    "}\n",
    "BUSINESS_FLAGS = {\n",
    "    'Patel' : 'patel_flag',\n",
    "    'TEAM'  : 'team_flag',\n",
    "    'Yellow': 'any_yellow_or_green_no_red',\n",
    "    'Green' : 'all_green'\n",
    "}\n",
    "\n",
    "BUS_HRS = range(8, 17)  # 08:00–16:59 inclusive\n",
    "\n",
    "# ── restrict to first 72 hours only ----------------------------------\n",
    "df_72h = final_df[final_df['time_from_vent'] <= 72].copy()\n",
    "\n",
    "# ── denominators -----------------------------------------------------\n",
    "total_patients        = df_72h['encounter_block'].nunique()\n",
    "total_observed_hours  = len(df_72h)\n",
    "total_business_hours  = len(df_72h[df_72h['recorded_hour'].isin(BUS_HRS)])\n",
    "\n",
    "# ── build aggregate rows --------------------------------------------\n",
    "rows = []\n",
    "for crit in CRITS_ALL:\n",
    "    f_all = CRITS_ALL[crit]\n",
    "    f_bus = BUSINESS_FLAGS[crit]\n",
    "\n",
    "    elig_all_df = df_72h[df_72h[f_all] == 1]\n",
    "    eligible_hours_all = len(elig_all_df)\n",
    "    eligible_patients = elig_all_df['encounter_block'].nunique()\n",
    "\n",
    "    elig_bus_df = df_72h[\n",
    "        (df_72h[f_bus] == 1) & (df_72h['recorded_hour'].isin(BUS_HRS))\n",
    "    ]\n",
    "    eligible_business_hours = len(elig_bus_df)\n",
    "\n",
    "    rows.append({\n",
    "        'Criteria'                      : crit,\n",
    "        'Total Patients'                : total_patients,\n",
    "        'Eligible Patients'             : eligible_patients,\n",
    "        'Total Observed Hours'          : total_observed_hours,\n",
    "        'Eligible Hours (all hrs)'      : eligible_hours_all,\n",
    "        'Total Business Hours'          : total_business_hours,\n",
    "        'Eligible Business Hours'       : eligible_business_hours,\n",
    "        'Proportion Eligible Hours %'   : 100 * eligible_hours_all / total_observed_hours,\n",
    "        'Proportion Eligible BusHrs %'  : 100 * eligible_business_hours / total_business_hours,\n",
    "        'Proportion Eligible Patients %': 100 * eligible_patients / total_patients\n",
    "    })\n",
    "\n",
    "aggregate_df = pd.DataFrame(rows)\n",
    "\n",
    "# Save the aggregate data to CSV\n",
    "timestamp = datetime.now().date()\n",
    "aggregate_df.to_csv(f'../output/final/aggregates_72hrs_{pyCLIF.helper[\"site_name\"]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d97c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom colors\n",
    "custom_colors = ['#983232', '#003f5c', '#fdfd96', '#98FB98']  # Maroon, Dark Blue, Pastel Yellow, Pastel Green\n",
    "# Plot proportion of eligible encounters\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible Patients %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible Patients %'], f\"{row['Proportion Eligible Patients %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Encounter (During first 72 hours)')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Encounters Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_encounters_72hrs_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible Hours %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible Hours %'], f\"{row['Proportion Eligible Hours %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Total Observed Hours (During first 72 hours)')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Observed Hours Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_total_hours_72hrs_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()\n",
    "\n",
    "# Define custom colors\n",
    "custom_colors = ['#983232', '#003f5c', '#fdfd96', '#98FB98']  # Maroon, Dark Blue, Pastel Yellow, Pastel Green\n",
    "\n",
    "# Plot proportion of eligible business hours\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible BusHrs %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible BusHrs %'], f\"{row['Proportion Eligible BusHrs %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Business Hours (During first 72 hours)')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Business Hours Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_business_hours_72hrs_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e6a1b",
   "metadata": {
    "papermill": {
     "duration": 0.010439,
     "end_time": "2025-05-05T20:36:56.667523",
     "exception": false,
     "start_time": "2025-05-05T20:36:56.657084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Aggregates for comparison across sites- Full Encounter Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8190d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:56.688459Z",
     "iopub.status.busy": "2025-05-05T20:36:56.688092Z",
     "iopub.status.idle": "2025-05-05T20:36:57.650763Z",
     "shell.execute_reply": "2025-05-05T20:36:57.650407Z"
    },
    "papermill": {
     "duration": 0.974292,
     "end_time": "2025-05-05T20:36:57.651852",
     "exception": false,
     "start_time": "2025-05-05T20:36:56.677560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "#  eligibility aggregates – ALL hours  vs  BUSINESS hours\n",
    "# --------------------------------------------------------------------\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ── flag dictionaries ------------------------------------------------\n",
    "CRITS_ALL = {                         # eligibility at *any* hour\n",
    "    'Patel' : 'patel_flag_all_hours',\n",
    "    'TEAM'  : 'team_flag_all_hours',\n",
    "    'Yellow': 'any_yellow_or_green_no_red_all_hours',\n",
    "    'Green' : 'all_green_all_hours',\n",
    "}\n",
    "# business‑hour flags you already calculate in final_df\n",
    "BUSINESS_FLAGS = dict([                 # eligibility at 8-16 inclusive hour\n",
    "    ('Patel' , 'patel_flag'),\n",
    "    ('TEAM'  , 'team_flag'),\n",
    "    ('Yellow', 'any_yellow_or_green_no_red'),\n",
    "    ('Green' , 'all_green')\n",
    "])\n",
    "\n",
    "BUS_HRS = range(8, 17)   # 08:00–16:59 inclusive\n",
    "\n",
    "# ── denominators -----------------------------------------------------\n",
    "total_patients        = final_df['encounter_block'].nunique()\n",
    "total_observed_hours  = len(final_df)\n",
    "total_business_hours  = len(final_df[final_df['recorded_hour'].isin(BUS_HRS)])\n",
    "\n",
    "# ── build aggregate rows --------------------------------------------\n",
    "rows = []\n",
    "for crit in CRITS_ALL:                # guarantees consistent order\n",
    "    f_all   = CRITS_ALL[crit]\n",
    "    f_bus   = BUSINESS_FLAGS[crit]\n",
    "    \n",
    "    # ALL‑hour eligibility\n",
    "    elig_all_df   = final_df[final_df[f_all] == 1]\n",
    "    eligible_hours_all = len(elig_all_df)\n",
    "    eligible_patients  = elig_all_df['encounter_block'].nunique()\n",
    "    \n",
    "    # BUSINESS‑hour eligibility\n",
    "    elig_bus_df = final_df[\n",
    "        (final_df[f_bus] == 1) & (final_df['recorded_hour'].isin(BUS_HRS))\n",
    "    ]\n",
    "    eligible_business_hours = len(elig_bus_df)\n",
    "    \n",
    "    rows.append({\n",
    "        'Criteria'                      : crit,\n",
    "        'Total Patients'                : total_patients,\n",
    "        'Eligible Patients'             : eligible_patients,\n",
    "        'Total Observed Hours'          : total_observed_hours,\n",
    "        'Eligible Hours (all hrs)'      : eligible_hours_all,\n",
    "        'Total Business Hours'          : total_business_hours,\n",
    "        'Eligible Business Hours'       : eligible_business_hours,\n",
    "        'Proportion Eligible Hours %'   : 100*eligible_hours_all/total_observed_hours,\n",
    "        'Proportion Eligible BusHrs %'  : 100*eligible_business_hours/total_business_hours,\n",
    "        'Proportion Eligible Patients %': 100*eligible_patients/total_patients\n",
    "    })\n",
    "\n",
    "aggregate_df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Save the aggregate data to CSV\n",
    "timestamp = datetime.now().date()\n",
    "aggregate_df.to_csv(f'../output/final/aggregates_{pyCLIF.helper[\"site_name\"]}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e43ed97",
   "metadata": {
    "papermill": {
     "duration": 0.010666,
     "end_time": "2025-05-05T20:36:57.672894",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.662228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Eligibility by encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b37027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:57.694268Z",
     "iopub.status.busy": "2025-05-05T20:36:57.694098Z",
     "iopub.status.idle": "2025-05-05T20:36:57.768036Z",
     "shell.execute_reply": "2025-05-05T20:36:57.767641Z"
    },
    "papermill": {
     "duration": 0.085894,
     "end_time": "2025-05-05T20:36:57.768894",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.683000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom colors\n",
    "custom_colors = ['#983232', '#003f5c', '#fdfd96', '#98FB98']  # Maroon, Dark Blue, Pastel Yellow, Pastel Green\n",
    "# Plot proportion of eligible encounters\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible Patients %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible Patients %'], f\"{row['Proportion Eligible Patients %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Encounter')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Encounters Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_encounters_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd8051",
   "metadata": {},
   "source": [
    "### Eligibility by all hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a96f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible Hours %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible Hours %'], f\"{row['Proportion Eligible Hours %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Total Observed Hours')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Observed Hours Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_total_hours_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e73f9",
   "metadata": {
    "papermill": {
     "duration": 0.010056,
     "end_time": "2025-05-05T20:36:57.789368",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.779312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Eligibility by business hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edaf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:57.810867Z",
     "iopub.status.busy": "2025-05-05T20:36:57.810707Z",
     "iopub.status.idle": "2025-05-05T20:36:57.888351Z",
     "shell.execute_reply": "2025-05-05T20:36:57.888018Z"
    },
    "papermill": {
     "duration": 0.089409,
     "end_time": "2025-05-05T20:36:57.889245",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.799836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom colors\n",
    "custom_colors = ['#983232', '#003f5c', '#fdfd96', '#98FB98']  # Maroon, Dark Blue, Pastel Yellow, Pastel Green\n",
    "\n",
    "# Plot proportion of eligible business hours\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot = sns.barplot(\n",
    "    x='Criteria', \n",
    "    y='Proportion Eligible BusHrs %', \n",
    "    data=aggregate_df, \n",
    "    palette=custom_colors\n",
    ")\n",
    "\n",
    "# Add percentages on top of the bars\n",
    "for index, row in aggregate_df.iterrows():\n",
    "    barplot.text(index, row['Proportion Eligible BusHrs %'], f\"{row['Proportion Eligible BusHrs %']:.1f}%\", \n",
    "                 color='black', ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Eligibility by Business Hours')\n",
    "plt.xlabel('Criteria')\n",
    "plt.ylabel('Percentage of Business Hours Eligible')\n",
    "\n",
    "# Save the graph\n",
    "plt.savefig(f'../output/final/graphs/eligibility_by_business_hours_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3190b",
   "metadata": {},
   "source": [
    "### Eligibility by business hour - One week trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44637a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUSINESS_FLAGS = dict([                 # eligibility at 8-16 inclusive hour\n",
    "    ('Patel' , 'patel_flag'),\n",
    "    ('TEAM'  , 'team_flag'),\n",
    "    ('Yellow', 'any_yellow_or_green_no_red'),\n",
    "    ('Green' , 'all_green')\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Restrict to first week (≤ 7 days = 168 hours) and bin by day\n",
    "# ---------------------------------------------------------------\n",
    "df_week = final_df.query(\"time_from_vent <= 168\").copy()\n",
    "df_week[\"day_bin\"] = (df_week[\"time_from_vent\"] // 24).astype(int)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Build trend DataFrame\n",
    "# ---------------------------------------------------------------\n",
    "trend_rows = []\n",
    "for crit, flag in BUSINESS_FLAGS.items():          # e.g. {'Patel': 'patel_flag', ...}\n",
    "    for day, g in df_week.groupby(\"day_bin\", sort=True):\n",
    "        # only count rows during business hours (8–16)\n",
    "        bus = g[g[\"recorded_hour\"].between(8, 16)]\n",
    "        denom = bus.shape[0]\n",
    "        num   = bus[bus[flag] == 1].shape[0]\n",
    "        prop  = num / denom if denom else np.nan\n",
    "        trend_rows.append({\n",
    "            \"criterion\": crit,\n",
    "            \"day\":       day,\n",
    "            \"prop_bus_hrs\": prop\n",
    "        })\n",
    "\n",
    "trend_df = pd.DataFrame(trend_rows)\n",
    "# save trend df\n",
    "trend_df.to_csv(f'../output/final/eligibility_trend_first_week_{pyCLIF.helper[\"site_name\"]}.csv', index=False)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Plot with custom colors\n",
    "# ---------------------------------------------------------------\n",
    "custom_colors = {\n",
    "    'Patel':  '#983232',  # maroon\n",
    "    'TEAM':   '#003f5c',  # dark blue\n",
    "    'Yellow': '#c9b037',  # pastel yellow\n",
    "    'Green':  '#2e8b57'   # pastel green\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(\n",
    "    data=trend_df,\n",
    "    x=\"day\",\n",
    "    y=\"prop_bus_hrs\",\n",
    "    hue=\"criterion\",\n",
    "    hue_order=list(custom_colors.keys()),\n",
    "    palette=custom_colors,\n",
    "    marker=\"o\",\n",
    "    linewidth=2\n",
    ")\n",
    "plt.xlabel(\"Days since intubation\")\n",
    "plt.ylabel(\"Proportion of business hours eligible\")\n",
    "plt.title(\"Eligibility trend — first week (Day 0-6)\")\n",
    "plt.xticks(range(0, 7))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title=\"Criterion\")\n",
    "plt.tight_layout()\n",
    "# save figure\n",
    "plt.savefig(\"../output/final/graphs/eligibility_trend_first_week.png\", dpi=300)\n",
    "# plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c80bb4",
   "metadata": {},
   "source": [
    "#### ECDF \n",
    "\n",
    "x‑axis (fraction of encounter hours eligible) – for each patient, what proportion of their ventilated hours satisfied the rule.\n",
    "y‑axis (proportion of patients ≤ x) – at any x, the height of a curve tells you what fraction of patients have eligibility no greater than x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (final_df\n",
    "       .groupby(['encounter_block'])\n",
    "       .agg(**{name: (flag, 'mean') for name, flag in CRITS_ALL.items()}))\n",
    "\n",
    "sns.ecdfplot(data=tmp.melt(var_name='criterion', value_name='pct'),\n",
    "             x='pct', hue='criterion')\n",
    "plt.xlabel('Fraction of encounter hours eligible')\n",
    "#save this plot\n",
    "plt.savefig(f'../output/final/graphs/eligibility_hour_ecdf_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb80d25",
   "metadata": {},
   "source": [
    "### Hourly distribution by hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0096dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ── convenience --------------------------------------------------------\n",
    "CRITS = {\n",
    "    'Patel' : 'patel_flag_all_hours',\n",
    "    'TEAM'  : 'team_flag_all_hours',\n",
    "    'Yellow': 'any_yellow_or_green_no_red_all_hours',\n",
    "    'Green' : 'all_green_all_hours',\n",
    "}\n",
    "BUS_HRS = range(8, 17)\n",
    "custom_colors = [\n",
    "    '#983232',  # Maroon\n",
    "    '#003f5c',  # Dark Blue\n",
    "    '#c9b037',  # Darker Yellow (Gold/Mustard tone)\n",
    "    '#2e8b57'   # Darker Green (Sea Green)\n",
    "]\n",
    "color_map = dict(zip(CRITS.keys(), custom_colors))\n",
    "\n",
    "# ── create combined hourly data (blocks per hour) ---------------------\n",
    "hourly_data = pd.DataFrame({'hour': range(24)})\n",
    "for name, flag in CRITS.items():\n",
    "    by_hour = (\n",
    "        final_df\n",
    "        .loc[final_df[flag] == 1, ['encounter_block','recorded_hour']]\n",
    "        .drop_duplicates()                                   # one row per block/hour\n",
    "        .groupby('recorded_hour')['encounter_block']\n",
    "        .nunique()                                          # count blocks\n",
    "        .reindex(range(24), fill_value=0)                   # ensure 0–23\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    hourly_data[name] = by_hour\n",
    "\n",
    "# ── melt for seaborn plotting ------------------------------------------\n",
    "hourly_melted = hourly_data.melt(\n",
    "    id_vars='hour',\n",
    "    var_name='Criteria',\n",
    "    value_name='Eligible Blocks'\n",
    ")\n",
    "#SAVE hourly_melted TO CSV\n",
    "hourly_melted.to_csv(f'../output/final/eligibility_hourly_melted_{pyCLIF.helper[\"site_name\"]}.csv', index=False)\n",
    "\n",
    "# ── plot ---------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "for crit, color in color_map.items():\n",
    "    sub = hourly_melted[hourly_melted['Criteria'] == crit]\n",
    "    plt.plot(sub['hour'], sub['Eligible Blocks'],\n",
    "             label=crit, marker='o', color=color)\n",
    "\n",
    "plt.axvspan(8, 17, color='orange', alpha=0.1, label='Business Hours')\n",
    "plt.title(\"Hourly Distribution of Eligible Blocks by Criteria\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Number of Eligible Blocks\")\n",
    "plt.xticks(range(24))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), title=\"Criterion\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# save\n",
    "plt.savefig(\n",
    "    f'../output/final/graphs/eligibility_hourly_distribution_blocks_{pyCLIF.helper[\"site_name\"]}.png',\n",
    "    dpi=300\n",
    ")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# totals = final_df.groupby(\"recorded_hour\").size()\n",
    "# totals.plot(marker=\"o\")\n",
    "# plt.title(\"All hourly rows by hour of day\")\n",
    "# plt.xlabel(\"Hour\")\n",
    "# plt.ylabel(\"Row count\")\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ef150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # raw hourly eligibility count\n",
    "# raw = final_df.groupby(\"recorded_hour\")[\"any_yellow_or_green_no_red\"].sum()\n",
    "\n",
    "# # block-level (all_hours) eligibility count\n",
    "# blk = final_df[ final_df[\"any_yellow_or_green_no_red_all_hours\"]==1 ] \\\n",
    "#       .groupby(\"recorded_hour\")[\"any_yellow_or_green_no_red_all_hours\"] \\\n",
    "#       .size()\n",
    "\n",
    "# pd.DataFrame({\n",
    "#     \"Total rows\": totals,\n",
    "#     \"Raw Yellow\": raw,\n",
    "#     \"Yellow (all_hours)\": blk\n",
    "# }).plot(marker=\"o\")\n",
    "# plt.title(\"Raw vs block-level Yellow eligibility\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64fa550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pick out only the hours where raw yellow drops most\n",
    "# drop_hours = raw.diff().nsmallest(3).index  # e.g. [8,9,10]\n",
    "\n",
    "# for hr in drop_hours:\n",
    "#     slice_hr = final_df[ final_df.recorded_hour == hr ]\n",
    "#     breakdown = {\n",
    "#       fld: slice_hr[fld].mean() \n",
    "#       for fld in [\n",
    "#         \"yellow_resp_spo2_flag\",\n",
    "#         \"yellow_fio2_flag\",\n",
    "#         \"yellow_resp_rate_flag\",\n",
    "#         \"yellow_peep_flag\",\n",
    "#         \"yellow_map_flag\",\n",
    "#         \"yellow_pulse_flag\",\n",
    "#         \"yellow_lactate_flag\"\n",
    "#       ]\n",
    "#     }\n",
    "#     print(f\"\\nHour {hr} fail-rate per subflag:\")\n",
    "#     for k,v in breakdown.items():\n",
    "#         print(f\"  {k}: {(1-v):.1%} failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159007eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# blocks_per_hour = (\n",
    "#     final_df\n",
    "#     .groupby(\"recorded_hour\")[\"encounter_block\"]\n",
    "#     .nunique()\n",
    "#     .reindex(range(24), fill_value=0)\n",
    "# )\n",
    "\n",
    "# blocks_per_hour.plot(marker=\"o\")\n",
    "# plt.title(\"Unique encounter_blocks by hour of day\")\n",
    "# plt.xlabel(\"Hour\")\n",
    "# plt.ylabel(\"Blocks with ANY row at that hour\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h7 = set(final_df.loc[final_df.recorded_hour==7,   \"encounter_block\"])\n",
    "# h8 = set(final_df.loc[final_df.recorded_hour==8,   \"encounter_block\"])\n",
    "# missing = list(h7 - h8)\n",
    "# print(\"Example blocks missing at 8 AM:\", missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5231f3",
   "metadata": {
    "papermill": {
     "duration": 0.010549,
     "end_time": "2025-05-05T20:36:57.910857",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.900308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Failure by subcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7753e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:57.933105Z",
     "iopub.status.busy": "2025-05-05T20:36:57.932926Z",
     "iopub.status.idle": "2025-05-05T20:36:59.144883Z",
     "shell.execute_reply": "2025-05-05T20:36:59.144592Z"
    },
    "papermill": {
     "duration": 1.223828,
     "end_time": "2025-05-05T20:36:59.145679",
     "exception": false,
     "start_time": "2025-05-05T20:36:57.921851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your criteria and corresponding subcomponent flags\n",
    "criteria_info = {\n",
    "    'patel_flag': {'resp_flag': 'patel_resp_flag', 'cardio_flag': 'patel_cardio_flag'},\n",
    "    'team_flag': {'resp_flag': 'team_resp_flag', 'cardio_flag': 'team_cardio_flag'},\n",
    "    'any_yellow_or_green_no_red': {'resp_flag': 'yellow_resp_flag', 'cardio_flag': 'yellow_cardio_flag'},\n",
    "    'all_green': {'resp_flag': 'green_resp_flag', 'cardio_flag': 'green_cardio_flag'}\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over each criterion\n",
    "for criterion, flags in criteria_info.items():\n",
    "    resp_flag = flags['resp_flag']\n",
    "    cardio_flag = flags['cardio_flag']\n",
    "    \n",
    "    # Calculate total hours per hospitalization_id\n",
    "    total_hours = final_df.groupby('encounter_block').size().rename('total_hours')\n",
    "    \n",
    "    # Create failure indicators\n",
    "    df_failure = final_df.copy()\n",
    "    df_failure['resp_only_failure'] = ((df_failure[resp_flag] == 0) & (df_failure[cardio_flag] == 1)).astype(int)\n",
    "    df_failure['cardio_only_failure'] = ((df_failure[resp_flag] == 1) & (df_failure[cardio_flag] == 0)).astype(int)\n",
    "    df_failure['both_failures'] = ((df_failure[resp_flag] == 0) & (df_failure[cardio_flag] == 0)).astype(int)\n",
    "    \n",
    "    # Aggregate the counts per hospitalization_id\n",
    "    failure_counts = df_failure.groupby('encounter_block')[['resp_only_failure', 'cardio_only_failure', 'both_failures']].sum()\n",
    "    \n",
    "    # Merge with total hours\n",
    "    failure_counts = failure_counts.merge(total_hours, left_index=True, right_index=True)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    failure_counts['resp_only_failure_perc'] = (failure_counts['resp_only_failure'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    failure_counts['cardio_only_failure_perc'] = (failure_counts['cardio_only_failure'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    failure_counts['both_failures_perc'] = (failure_counts['both_failures'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    \n",
    "    # Calculate total failure percentage\n",
    "    failure_counts['total_failure_perc'] = (\n",
    "        failure_counts['resp_only_failure'] + failure_counts['cardio_only_failure'] + failure_counts['both_failures']\n",
    "    ) * 100 / failure_counts['total_hours']\n",
    "    \n",
    "    # Calculate criterion met percentage\n",
    "    criterion_met = final_df.groupby('encounter_block')[criterion].sum().rename('criterion_met_hours')\n",
    "    failure_counts = failure_counts.merge(criterion_met, left_index=True, right_index=True)\n",
    "    failure_counts['criterion_met_perc'] = (failure_counts['criterion_met_hours'] * 100 / failure_counts['total_hours']).round(3)\n",
    "    \n",
    "    # Add criterion name to the DataFrame\n",
    "    failure_counts['Criteria'] = criterion\n",
    "    \n",
    "    # Append to results\n",
    "    results.append(failure_counts.reset_index())\n",
    "\n",
    "# Concatenate results for all criteria\n",
    "all_failure_counts = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Now, calculate the average percentages across all hospitalizations for each criterion\n",
    "avg_failure_percentages = all_failure_counts.groupby('Criteria').agg({\n",
    "    'resp_only_failure_perc': 'mean',\n",
    "    'cardio_only_failure_perc': 'mean',\n",
    "    'both_failures_perc': 'mean',\n",
    "    'total_failure_perc': 'mean',\n",
    "    'criterion_met_perc': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "avg_failure_percentages = avg_failure_percentages.rename(columns={\n",
    "    'resp_only_failure_perc': 'Resp Failure Only',\n",
    "    'cardio_only_failure_perc': 'Cardio Failure Only',\n",
    "    'both_failures_perc': 'Both Failures',\n",
    "    'total_failure_perc': 'Total Failure',\n",
    "    'criterion_met_perc': 'Criterion Met'\n",
    "})\n",
    "\n",
    "# Display the average failure percentages\n",
    "criteria_mapping = {\n",
    "    'patel_flag': 'Patel',\n",
    "    'team_flag': 'TEAM',\n",
    "    'any_yellow_or_green_no_red': 'Yellow',\n",
    "    'all_green': 'Green'\n",
    "}\n",
    "\n",
    "avg_failure_percentages['Criteria'] = avg_failure_percentages['Criteria'].replace(criteria_mapping)\n",
    "avg_failure_percentages['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(avg_failure_percentages).to_csv(f'../output/final/avg_failure_percentages_{pyCLIF.helper[\"site_name\"]}.csv',index=False)\n",
    "avg_failure_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04691f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:36:59.168310Z",
     "iopub.status.busy": "2025-05-05T20:36:59.168158Z",
     "iopub.status.idle": "2025-05-05T20:37:00.142583Z",
     "shell.execute_reply": "2025-05-05T20:37:00.142184Z"
    },
    "papermill": {
     "duration": 1.033448,
     "end_time": "2025-05-05T20:37:00.190042",
     "exception": false,
     "start_time": "2025-05-05T20:36:59.156594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kaleido\n",
    "import plotly.graph_objects as go\n",
    "# Create a stacked bar plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for Cardio Failure Only\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Cardio Failure Only'],\n",
    "    name='Cardio Failure Only',\n",
    "    marker_color='#003366'  # Dark Blue\n",
    "))\n",
    "\n",
    "# Add bars for Resp Failure Only\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Resp Failure Only'],\n",
    "    name='Resp Failure Only',\n",
    "    marker_color='#983232'  # Maroon\n",
    "))\n",
    "\n",
    "# Add bars for Both Failures\n",
    "fig.add_trace(go.Bar(\n",
    "    x=avg_failure_percentages['Criteria'],\n",
    "    y=avg_failure_percentages['Both Failures'],\n",
    "    name='Both Failures',\n",
    "    marker_color='#fdfd96'  # Pastel Yellow\n",
    "))\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    xaxis_title='Criteria',\n",
    "    yaxis_title='Average Percentage of Business Hours Not Met (%)',\n",
    "    yaxis=dict(range=[0, 100]),\n",
    "    template='plotly_white',\n",
    "    legend_title='Failure Type'\n",
    ")\n",
    "# Save the plot\n",
    "fig.write_image(f'../output/final/graphs/avg_failure_components_{pyCLIF.helper[\"site_name\"]}_{datetime.now().date()}.png')\n",
    "# Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd2f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:00.300456Z",
     "iopub.status.busy": "2025-05-05T20:37:00.300291Z",
     "iopub.status.idle": "2025-05-05T20:37:00.308364Z",
     "shell.execute_reply": "2025-05-05T20:37:00.308037Z"
    },
    "papermill": {
     "duration": 0.064543,
     "end_time": "2025-05-05T20:37:00.309250",
     "exception": false,
     "start_time": "2025-05-05T20:37:00.244707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────\n",
    "#  analyse_criterion.py  – plug‑and‑play helper\n",
    "# ────────────────────────────────────────────────────────────\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from upsetplot import from_indicators, UpSet\n",
    "from pathlib   import Path\n",
    "\n",
    "def analyse_criterion(\n",
    "    df: pd.DataFrame,\n",
    "    crit_name: str,\n",
    "    *,\n",
    "    flag_cols: list,             # list of sub‑criterion flags (0/1)\n",
    "    master_flag: str,            # overall eligibility flag (0/1)\n",
    "    id_col: str        = \"encounter_block\",\n",
    "    time_col: str      = \"time_from_vent\",\n",
    "    out_dir           = \"../output/final\",\n",
    "    save_fig_data: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    • Find blocks that *never* satisfy `master_flag`\n",
    "    • For those blocks …\n",
    "        - how often is each sub-flag FALSE?\n",
    "        - which sub-flag is the *latest* to turn TRUE       (primary blocker)\n",
    "        - which combinations of sub-flags ever fail (UpSet)\n",
    "        - optionally: a distribution plot of a dose / lab   (pass in yourself)\n",
    "\n",
    "    Everything (plots + .csv helpers) is written to `out_dir/crit_name/`.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir, crit_name.lower())\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ── 1 · which blocks NEVER became eligible? ─────────────────────────\n",
    "    never = (df.groupby(id_col)[master_flag].max()\n",
    "               .reset_index(name=\"ever\")[lambda d: d[\"ever\"] == 0]\n",
    "               .drop(columns=\"ever\"))\n",
    "    fail  = never.merge(df, on=id_col, how=\"inner\")\n",
    "    print(f\"[{crit_name}] {fail[id_col].nunique()} blocks never became eligible\")\n",
    "\n",
    "    # ── 2 · proportion of hours each sub‑flag is FALSE ──────────────────\n",
    "    long = fail.melt(id_vars=[id_col], value_vars=flag_cols,\n",
    "                     var_name=\"criterion\", value_name=\"flag\")\n",
    "    summary = (long.groupby(\"criterion\")[\"flag\"]\n",
    "                     .apply(lambda s: (s == 0).mean())\n",
    "                     .rename(\"prop_hours_failed\")\n",
    "                     .reset_index()\n",
    "                     .sort_values(\"prop_hours_failed\", ascending=False))\n",
    "\n",
    "    if save_fig_data:\n",
    "        summary.to_csv(out_dir/\"subflag_failure_rates.csv\", index=False)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.barh(summary[\"criterion\"], summary[\"prop_hours_failed\"])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Proportion of hours NOT satisfied\")\n",
    "    plt.title(f\"{crit_name}: which sub‑criteria blocked eligibility?\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir/\"subflag_bar.png\", dpi=300);  plt.close()\n",
    "\n",
    "    # ── 3 · “primary blocker” per block (latest first‑TRUE) ─────────────\n",
    "    def first_true(g, col):\n",
    "        hit = g.loc[g[col] == 1, time_col]\n",
    "        return hit.min() if not hit.empty else np.inf\n",
    "\n",
    "    prim = []\n",
    "    for blk, g in fail.groupby(id_col):\n",
    "        lags = {c: first_true(g, c) for c in flag_cols}\n",
    "        prim_blk = max(lags, key=lags.get)\n",
    "        prim.append([blk, prim_blk])\n",
    "\n",
    "    prim_df = pd.DataFrame(prim, columns=[id_col, \"primary_blocker\"])\n",
    "    # prim_df.to_csv(out_dir/\"primary_blocker_per_block.csv\", index=False)\n",
    "\n",
    "    # ── 4 · UpSet plot of sub‑flag combinations that *ever* fail ────────\n",
    "    failed = fail[flag_cols].eq(0)                   # True => criterion failed\n",
    "    block_fail = failed.groupby(fail[id_col]).max()  # at any hour in block\n",
    "    upset_data = from_indicators(block_fail.columns, block_fail)\n",
    "\n",
    "    UpSet(upset_data, show_counts=True,\n",
    "          sort_by=\"cardinality\").plot()\n",
    "    plt.suptitle(f\"{crit_name}: combinations of failed sub‑criteria\")\n",
    "    plt.savefig(out_dir/\"upset.png\", dpi=300);  plt.close()\n",
    "\n",
    "    # ── 5 · quick dose distribution (example: NE)  ----------------------\n",
    "    if \"ne_calc_max\" in fail.columns:\n",
    "        sns.histplot(fail[\"ne_calc_max\"], bins=40, kde=False)\n",
    "        plt.axvline(0.2, color=\"red\", ls=\"--\")\n",
    "        plt.title(f\"{crit_name}: hourly max NE dose (only failed blocks)\")\n",
    "        plt.xlabel(\"µg/kg/min\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir/\"ne_hist.png\", dpi=300);  plt.close()\n",
    "\n",
    "    print(f\"[{crit_name}] figures + CSV written to {out_dir}\\n\")\n",
    "    return summary, prim_df\n",
    "# ────────────────────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47de5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:00.456975Z",
     "iopub.status.busy": "2025-05-05T20:37:00.456805Z",
     "iopub.status.idle": "2025-05-05T20:37:01.745295Z",
     "shell.execute_reply": "2025-05-05T20:37:01.744864Z"
    },
    "papermill": {
     "duration": 1.381707,
     "end_time": "2025-05-05T20:37:01.746385",
     "exception": false,
     "start_time": "2025-05-05T20:37:00.364678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- define once --------------------------------------------------------\n",
    "team_flags = [\"team_pulse_flag\", \"team_lactate_flag\", \"team_ne_flag\",\n",
    "              \"team_fio2_flag\",  \"team_peep_flag\",    \"team_resp_rate_flag\"]\n",
    "\n",
    "# --- call helper --------------------------------------------------------\n",
    "summary_team, primary_team = analyse_criterion(\n",
    "    final_df,                      # your long hourly dataframe\n",
    "    crit_name  = \"TEAM\",\n",
    "    flag_cols  = team_flags,\n",
    "    master_flag= \"team_flag\",      # overall TEAM eligibility flag\n",
    "    out_dir    = \"../output/final\"   # everything will live in …/figures/team/\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a1e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:01.859452Z",
     "iopub.status.busy": "2025-05-05T20:37:01.859220Z",
     "iopub.status.idle": "2025-05-05T20:37:05.646608Z",
     "shell.execute_reply": "2025-05-05T20:37:05.646276Z"
    },
    "papermill": {
     "duration": 3.846229,
     "end_time": "2025-05-05T20:37:05.647477",
     "exception": false,
     "start_time": "2025-05-05T20:37:01.801248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_yellow_fields =[\n",
    "    # Red Flags\n",
    "    'red_resp_spo2_flag', 'red_map_flag', 'red_high_support_flag',\n",
    "    'red_hypertensive_flag', 'red_pulse_high_flag', 'red_pulse_low_flag',\n",
    "    \n",
    "    # Yellow Flags\n",
    "    'yellow_resp_spo2_flag', 'yellow_fio2_flag', 'yellow_resp_rate_flag',\n",
    "    'yellow_peep_flag', 'yellow_map_flag', 'yellow_pulse_flag',\n",
    "    'yellow_lactate_flag',\n",
    "    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    \n",
    "    # Composite Flags\n",
    "    'any_red', 'any_yellow', 'any_green', 'all_green',\n",
    "    'all_green_no_red', 'all_green_no_red_yellow',\n",
    "    'all_yellow_no_red_green', 'any_yellow_no_red_green',\n",
    "    'any_yellow_or_green_no_red', 'yellow_resp_flag',\n",
    "    'yellow_cardio_flag', 'yellow_all_green', 'yellow_not_all_green'\n",
    "]\n",
    "\n",
    "summary_yel, primary_yel = analyse_criterion(\n",
    "    final_df,\n",
    "    crit_name  = \"Yellow\",\n",
    "    flag_cols  = reqd_yellow_fields,\n",
    "    master_flag= \"any_yellow_or_green_no_red\"          # <- whatever your overall column is called\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:05.760803Z",
     "iopub.status.busy": "2025-05-05T20:37:05.760622Z",
     "iopub.status.idle": "2025-05-05T20:37:07.394332Z",
     "shell.execute_reply": "2025-05-05T20:37:07.393997Z"
    },
    "papermill": {
     "duration": 1.692266,
     "end_time": "2025-05-05T20:37:07.395199",
     "exception": false,
     "start_time": "2025-05-05T20:37:05.702933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_patel_fields = ['patel_map_flag','patel_sbp_flag','patel_pulse_flag', \n",
    "                    'patel_resp_rate_flag' , 'patel_spo2_flag', 'patel_resp_flag', 'patel_cardio_flag', 'patel_flag' ]\n",
    "\n",
    "summary_patel, primary_patel = analyse_criterion(\n",
    "    final_df,\n",
    "    crit_name  = \"Patel\",\n",
    "    flag_cols  = reqd_patel_fields,\n",
    "    master_flag= \"patel_flag\"          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df8734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:07.509154Z",
     "iopub.status.busy": "2025-05-05T20:37:07.508968Z",
     "iopub.status.idle": "2025-05-05T20:37:11.682887Z",
     "shell.execute_reply": "2025-05-05T20:37:11.682520Z"
    },
    "papermill": {
     "duration": 4.233444,
     "end_time": "2025-05-05T20:37:11.683814",
     "exception": false,
     "start_time": "2025-05-05T20:37:07.450370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reqd_green_fields =[    \n",
    "    # Green Flags\n",
    "    'green_resp_spo2_flag', 'green_resp_rate_flag', 'green_fio2_flag',\n",
    "    'green_peep_flag', 'green_map_flag', 'green_pulse_flag',\n",
    "    'green_lactate_flag', 'green_hr_flag',\n",
    "    \n",
    "    # Composite Flags\n",
    "     'all_green',\n",
    "    'all_green_no_red', \n",
    "]\n",
    "\n",
    "summary_green, primary_green = analyse_criterion(\n",
    "    final_df,\n",
    "    crit_name  = \"Green\",\n",
    "    flag_cols  = reqd_green_fields,\n",
    "    master_flag= \"all_green\"          \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8f6d4",
   "metadata": {
    "papermill": {
     "duration": 0.056541,
     "end_time": "2025-05-05T20:37:15.482773",
     "exception": false,
     "start_time": "2025-05-05T20:37:15.426232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Average Hours Criteria Met on Days 1, 2, and 3\n",
    "\n",
    "Determine how many hours the criteria are met on specific calendar days (Day 1, Day 2, Day 3 after intubation).\n",
    "\n",
    "1. First, assign a calendar_day column that represents the calendar day relative to intubation.\n",
    "2. Use the recorded_date and recorded hour to calculate the difference from the intubation time, and categorize rows into Day 1, Day 2, Day 3.\n",
    "3. For each encounter, group the data by calendar_day and hospitalization_id and sum the hours that meet each criterion.\n",
    "4. Compute the average number of hours for each criterion per day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a477d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:15.701276Z",
     "iopub.status.busy": "2025-05-05T20:37:15.699062Z",
     "iopub.status.idle": "2025-05-05T20:37:16.399843Z",
     "shell.execute_reply": "2025-05-05T20:37:16.399545Z"
    },
    "papermill": {
     "duration": 0.830447,
     "end_time": "2025-05-05T20:37:16.400676",
     "exception": false,
     "start_time": "2025-05-05T20:37:15.570229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge final_df with vent_start_end to get 'vent_start_time'\n",
    "visualization_df = pd.merge(\n",
    "    final_df,\n",
    "    all_ids_w_outcome[['encounter_block', 'block_vent_start_dttm']],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Ensure 'vent_start_time' and 'recorded_date' are in datetime format\n",
    "visualization_df['block_vent_start_dttm'] = pd.to_datetime(visualization_df['block_vent_start_dttm'])\n",
    "visualization_df['recorded_date'] = pd.to_datetime(visualization_df['recorded_date'])\n",
    "\n",
    "# Combine 'recorded_date' and 'recorded_hour' to create 'recorded_dttm'\n",
    "visualization_df['recorded_dttm'] = visualization_df['recorded_date'] + pd.to_timedelta(visualization_df['recorded_hour'], unit='h')\n",
    "\n",
    "# Verify the data types\n",
    "# print(\"Verify data types\\n\", visualization_df[['vent_start_time', 'recorded_dttm']].dtypes)\n",
    "\n",
    "# Remove timezone information from 'vent_start_time' if it's timezone-aware\n",
    "if visualization_df['block_vent_start_dttm'].dt.tz is not None:\n",
    "    visualization_df['block_vent_start_dttm'] = visualization_df['block_vent_start_dttm'].dt.tz_localize(None)\n",
    "\n",
    "# Similarly, remove timezone information from 'recorded_dttm' if needed\n",
    "if visualization_df['recorded_dttm'].dt.tz is not None:\n",
    "    visualization_df['recorded_dttm'] = visualization_df['recorded_dttm'].dt.tz_localize(None)\n",
    "\n",
    "# print(\"\\nConverted data type if not tz naive\\n\", visualization_df[['vent_start_time', 'recorded_dttm']].dtypes)\n",
    "\n",
    "def assign_calendar_day(df, intubation_col, recorded_col):\n",
    "    # Calculate the difference in days between intubation and recorded time\n",
    "    df['calendar_day'] = (df[recorded_col] - df[intubation_col]).dt.days + 1\n",
    "    return df\n",
    "\n",
    "# Assign calendar day for each encounter\n",
    "visualization_df = assign_calendar_day(visualization_df, 'block_vent_start_dttm', 'recorded_dttm')\n",
    "\n",
    "visualization_df = visualization_df[['encounter_block', 'block_vent_start_dttm', 'recorded_dttm', \n",
    "                  'calendar_day', 'patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green', 'all_green_no_red',\n",
    "                  'any_green']]\n",
    "\n",
    "def compute_avg_hours_by_day(df, criteria_columns):\n",
    "    # Ensure hospitalization_id is handled as string/object and numeric columns as numbers\n",
    "    hours_per_day = df.groupby(['encounter_block', 'calendar_day']).agg({\n",
    "        'patel_flag': 'sum',\n",
    "        'team_flag': 'sum',\n",
    "        'any_yellow_or_green_no_red': 'sum',\n",
    "        'all_green': 'sum',\n",
    "    }).reset_index()\n",
    "    # Filter for Day 1, Day 2, Day 3\n",
    "    hours_per_day = hours_per_day[hours_per_day['calendar_day'].isin([1, 2, 3])]\n",
    "    \n",
    "    # Calculate the average number of hours for each day\n",
    "    avg_hours_by_day = hours_per_day.groupby('calendar_day').agg({\n",
    "        'patel_flag': 'mean',\n",
    "        'team_flag': 'mean',\n",
    "        'any_yellow_or_green_no_red': 'mean',\n",
    "        'all_green': 'mean',\n",
    "    }).reset_index()\n",
    "    \n",
    "    return avg_hours_by_day\n",
    "\n",
    "# Define your criteria columns\n",
    "criteria_columns = ['patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green']\n",
    "# Calculate the average number of hours each criterion is met on Day 1, 2, and 3\n",
    "avg_hours_by_day = compute_avg_hours_by_day(visualization_df, criteria_columns)\n",
    "avg_hours_by_day['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(avg_hours_by_day).to_csv(f'../output/final/avg_hours_by_day_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "\n",
    "def plot_avg_hours_by_day_bar(avg_hours_by_day, criteria_columns):\n",
    "    # Melt the DataFrame for easier plotting with seaborn\n",
    "    melted_df = avg_hours_by_day.melt(id_vars='calendar_day', value_vars=criteria_columns, var_name='Criteria', value_name='Average Hours Met')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a bar plot\n",
    "    sns.barplot(x='calendar_day', y='Average Hours Met', hue='Criteria', data=melted_df, palette='viridis')\n",
    "    \n",
    "    # Add custom x-axis labels for Day 1, Day 2, Day 3\n",
    "    plt.xticks(ticks=[0, 1, 2], labels=[\"Day 1\", \"Day 2\", \"Day 3\"])\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Average Hours Criteria Met per Day')\n",
    "    plt.xlabel('Calendar Day')\n",
    "    plt.ylabel('Average Hours Criteria Met')\n",
    "    \n",
    "    # Move the legend to the bottom\n",
    "    plt.legend(title='Criteria', loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plt.savefig(f'../output/final/graphs/avg_hours_by_day_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the average hours by day using a bar plot\n",
    "plot_avg_hours_by_day_bar(avg_hours_by_day, criteria_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa9f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:16.515265Z",
     "iopub.status.busy": "2025-05-05T20:37:16.515093Z",
     "iopub.status.idle": "2025-05-05T20:37:16.758084Z",
     "shell.execute_reply": "2025-05-05T20:37:16.757450Z"
    },
    "papermill": {
     "duration": 0.301423,
     "end_time": "2025-05-05T20:37:16.759290",
     "exception": false,
     "start_time": "2025-05-05T20:37:16.457867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge final_df with vent_start_end to get 'vent_start_time'\n",
    "visualization_df = pd.merge(\n",
    "    df_72h,\n",
    "    all_ids_w_outcome[['encounter_block', 'block_vent_start_dttm']],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Ensure 'vent_start_time' and 'recorded_date' are in datetime format\n",
    "visualization_df['block_vent_start_dttm'] = pd.to_datetime(visualization_df['block_vent_start_dttm'])\n",
    "visualization_df['recorded_date'] = pd.to_datetime(visualization_df['recorded_date'])\n",
    "\n",
    "# Combine 'recorded_date' and 'recorded_hour' to create 'recorded_dttm'\n",
    "visualization_df['recorded_dttm'] = visualization_df['recorded_date'] + pd.to_timedelta(visualization_df['recorded_hour'], unit='h')\n",
    "\n",
    "# Verify the data types\n",
    "# print(\"Verify data types\\n\", visualization_df[['vent_start_time', 'recorded_dttm']].dtypes)\n",
    "\n",
    "# Remove timezone information from 'vent_start_time' if it's timezone-aware\n",
    "if visualization_df['block_vent_start_dttm'].dt.tz is not None:\n",
    "    visualization_df['block_vent_start_dttm'] = visualization_df['block_vent_start_dttm'].dt.tz_localize(None)\n",
    "\n",
    "# Similarly, remove timezone information from 'recorded_dttm' if needed\n",
    "if visualization_df['recorded_dttm'].dt.tz is not None:\n",
    "    visualization_df['recorded_dttm'] = visualization_df['recorded_dttm'].dt.tz_localize(None)\n",
    "\n",
    "# print(\"\\nConverted data type if not tz naive\\n\", visualization_df[['vent_start_time', 'recorded_dttm']].dtypes)\n",
    "\n",
    "def assign_calendar_day(df, intubation_col, recorded_col):\n",
    "    # Calculate the difference in days between intubation and recorded time\n",
    "    df['calendar_day'] = (df[recorded_col] - df[intubation_col]).dt.days + 1\n",
    "    return df\n",
    "\n",
    "# Assign calendar day for each encounter\n",
    "visualization_df = assign_calendar_day(visualization_df, 'block_vent_start_dttm', 'recorded_dttm')\n",
    "\n",
    "visualization_df = visualization_df[['encounter_block', 'block_vent_start_dttm', 'recorded_dttm', \n",
    "                  'calendar_day', 'patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green', 'all_green_no_red',\n",
    "                  'any_green']]\n",
    "\n",
    "def compute_avg_hours_by_day(df, criteria_columns):\n",
    "    # Ensure hospitalization_id is handled as string/object and numeric columns as numbers\n",
    "    hours_per_day = df.groupby(['encounter_block', 'calendar_day']).agg({\n",
    "        'patel_flag': 'sum',\n",
    "        'team_flag': 'sum',\n",
    "        'any_yellow_or_green_no_red': 'sum',\n",
    "        'all_green': 'sum',\n",
    "    }).reset_index()\n",
    "    # Filter for Day 1, Day 2, Day 3\n",
    "    hours_per_day = hours_per_day[hours_per_day['calendar_day'].isin([1, 2, 3])]\n",
    "    \n",
    "    # Calculate the average number of hours for each day\n",
    "    avg_hours_by_day = hours_per_day.groupby('calendar_day').agg({\n",
    "        'patel_flag': 'mean',\n",
    "        'team_flag': 'mean',\n",
    "        'any_yellow_or_green_no_red': 'mean',\n",
    "        'all_green': 'mean',\n",
    "    }).reset_index()\n",
    "    \n",
    "    return avg_hours_by_day\n",
    "\n",
    "# Define your criteria columns\n",
    "criteria_columns = ['patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green']\n",
    "# Calculate the average number of hours each criterion is met on Day 1, 2, and 3\n",
    "avg_hours_by_day = compute_avg_hours_by_day(visualization_df, criteria_columns)\n",
    "avg_hours_by_day['site_name'] = pyCLIF.helper[\"site_name\"]\n",
    "pd.DataFrame(avg_hours_by_day).to_csv(f'../output/final/avg_hours_by_day_72h_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "\n",
    "def plot_avg_hours_by_day_bar(avg_hours_by_day, criteria_columns):\n",
    "    # Melt the DataFrame for easier plotting with seaborn\n",
    "    melted_df = avg_hours_by_day.melt(id_vars='calendar_day', value_vars=criteria_columns, var_name='Criteria', value_name='Average Hours Met')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create a bar plot\n",
    "    sns.barplot(x='calendar_day', y='Average Hours Met', hue='Criteria', data=melted_df, palette='viridis')\n",
    "    \n",
    "    # Add custom x-axis labels for Day 1, Day 2, Day 3\n",
    "    plt.xticks(ticks=[0, 1, 2], labels=[\"Day 1\", \"Day 2\", \"Day 3\"])\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Average Hours Criteria Met per Day')\n",
    "    plt.xlabel('Calendar Day')\n",
    "    plt.ylabel('Average Hours Criteria Met')\n",
    "    \n",
    "    # Move the legend to the bottom\n",
    "    plt.legend(title='Criteria', loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    # Save the plot\n",
    "    plt.savefig(f'../output/final/graphs/avg_hours_by_day_72h_{pyCLIF.helper[\"site_name\"]}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Plot the average hours by day using a bar plot\n",
    "plot_avg_hours_by_day_bar(avg_hours_by_day, criteria_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e14e32",
   "metadata": {
    "papermill": {
     "duration": 0.064638,
     "end_time": "2025-05-05T20:37:16.904678",
     "exception": false,
     "start_time": "2025-05-05T20:37:16.840040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Parallel categories plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc89cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:17.020495Z",
     "iopub.status.busy": "2025-05-05T20:37:17.020288Z",
     "iopub.status.idle": "2025-05-05T20:37:19.945729Z",
     "shell.execute_reply": "2025-05-05T20:37:19.945318Z"
    },
    "papermill": {
     "duration": 2.98513,
     "end_time": "2025-05-05T20:37:19.946835",
     "exception": false,
     "start_time": "2025-05-05T20:37:16.961705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Useful for EDA \n",
    "# Create a DataFrame for parallel categories plot\n",
    "parallel_df = final_df[['patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green']].copy()\n",
    "parallel_df['patel_flag'] = parallel_df['patel_flag'].apply(lambda x: 1 if x else 0)\n",
    "parallel_df['team_flag'] = parallel_df['team_flag'].apply(lambda x: 1 if x else 0)\n",
    "parallel_df['any_yellow_or_green_no_red'] = parallel_df['any_yellow_or_green_no_red'].apply(lambda x: 1 if x else 0)\n",
    "parallel_df['all_green'] = parallel_df['all_green'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "# Create parallel categories plot\n",
    "fig = px.parallel_categories(parallel_df, dimensions=['patel_flag', 'team_flag', 'any_yellow_or_green_no_red', 'all_green'],\n",
    "                             color=\"patel_flag\",\n",
    "                             labels={'patel_flag': 'Patel Met', 'team_flag': 'TEAM Met', 'any_yellow_or_green_no_red': 'Yellow Flag', 'all_green': 'Green Flag'},\n",
    "                             color_continuous_scale=px.colors.sequential.Inferno)\n",
    "\n",
    "fig.update_layout(title=\"Parallel Categories Plot: Comparison of Criteria Satisfaction\")\n",
    "\n",
    "# Save the final figure\n",
    "fig.write_image(f'../output/final/graphs/parallel_categories_{pyCLIF.helper[\"site_name\"]}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558437d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:20.295865Z",
     "iopub.status.busy": "2025-05-05T20:37:20.295019Z",
     "iopub.status.idle": "2025-05-05T20:37:20.396770Z",
     "shell.execute_reply": "2025-05-05T20:37:20.396321Z"
    },
    "papermill": {
     "duration": 0.280801,
     "end_time": "2025-05-05T20:37:20.397748",
     "exception": false,
     "start_time": "2025-05-05T20:37:20.116947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at encounters when Patel flag is not met but team flag is met\n",
    "## sanity check\n",
    "patel_fail_team_pass = final_df[(final_df['patel_flag'] == 0) & (final_df['team_flag'] == 1)]\n",
    "# Verify the filter\n",
    "print(f\"\\nTotal number of hours where Patel failed and Team passed: {len(patel_fail_team_pass)}\\n\")\n",
    "\n",
    "if len(patel_fail_team_pass) > 0:\n",
    "    # Dictionary to store our failure counts\n",
    "    print(\"Primary cause of Patel Criteria non-compliance\")\n",
    "    failure_counts = {\n",
    "            'MAP': sum(patel_fail_team_pass['patel_map_flag'] == 0),\n",
    "            'SBP': sum(patel_fail_team_pass['patel_sbp_flag'] == 0),\n",
    "            'Pulse': sum(patel_fail_team_pass['patel_pulse_flag'] == 0),\n",
    "            'Respiratory Rate': sum(patel_fail_team_pass['patel_resp_rate_flag'] == 0),\n",
    "            'SpO2': sum(patel_fail_team_pass['patel_spo2_flag'] == 0)\n",
    "        }\n",
    "    failure_df = pd.DataFrame(list(failure_counts.items()),columns = ['Criteria','Count'])\n",
    "    failure_df.to_csv(f'../output/final/patel_fail_team_pass_subcomponents_{pyCLIF.helper[\"site_name\"]}_{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.csv',index=False)\n",
    "    print(failure_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8312bc",
   "metadata": {
    "papermill": {
     "duration": 0.177862,
     "end_time": "2025-05-05T20:37:20.793285",
     "exception": false,
     "start_time": "2025-05-05T20:37:20.615423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Yellow-Green spectrum criteria distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca6640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:21.318270Z",
     "iopub.status.busy": "2025-05-05T20:37:21.317719Z",
     "iopub.status.idle": "2025-05-05T20:37:21.937724Z",
     "shell.execute_reply": "2025-05-05T20:37:21.937253Z"
    },
    "papermill": {
     "duration": 0.812387,
     "end_time": "2025-05-05T20:37:21.938873",
     "exception": false,
     "start_time": "2025-05-05T20:37:21.126486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# which sub‑criteria are green / yellow\n",
    "green_cols  = [c for c in final_df.columns if c.startswith(\"green_\") and c.endswith(\"_flag\")]\n",
    "yellow_cols = [c for c in final_df.columns if c.startswith(\"yellow_\") and c.endswith(\"_flag\")]\n",
    "\n",
    "# one row per block at the moment it first became eligible\n",
    "first_hit = (\n",
    "    final_df.loc[final_df[\"any_yellow_or_green_no_red\"] == 1]\n",
    "             .sort_values([\"encounter_block\", \"time_from_vent\"])\n",
    "             .groupby(\"encounter_block\")\n",
    "             .first()\n",
    ")\n",
    "\n",
    "# count how many green / yellow sub‑criteria were satisfied at that hour\n",
    "first_hit[\"n_green\"]  = first_hit[green_cols].sum(axis=1)\n",
    "first_hit[\"n_yellow\"] = first_hit[yellow_cols].sum(axis=1)\n",
    "\n",
    "# yellow‑fraction: 0 = all satisfied criteria were green, 1 = all yellow\n",
    "first_hit[\"yellow_frac\"] = (\n",
    "    first_hit[\"n_yellow\"] /\n",
    "    (first_hit[\"n_green\"] + first_hit[\"n_yellow\"])\n",
    ").fillna(0)              # guard against division by zero\n",
    "\n",
    "# yellow‑fraction: 0 = all satisfied criteria were green, 1 = all yellow\n",
    "first_hit[\"green_frac\"] = (\n",
    "    first_hit[\"n_green\"] /\n",
    "    (first_hit[\"n_green\"] + first_hit[\"n_yellow\"])\n",
    ").fillna(0)              # guard against division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2932ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T20:37:22.283936Z",
     "iopub.status.busy": "2025-05-05T20:37:22.283744Z",
     "iopub.status.idle": "2025-05-05T20:37:22.875162Z",
     "shell.execute_reply": "2025-05-05T20:37:22.874659Z"
    },
    "papermill": {
     "duration": 0.785929,
     "end_time": "2025-05-05T20:37:22.876437",
     "exception": false,
     "start_time": "2025-05-05T20:37:22.090508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  Build the jittered scatter data  (unchanged)\n",
    "# ------------------------------------------------------------\n",
    "x = np.random.normal(0, 0.002, size=len(first_hit))   # tiny horizontal jitter\n",
    "y = first_hit[\"green_frac\"].values                    # 1 = pure green, 0 = pure yellow\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Custom colormap: pure‑green  →  pure‑yellow\n",
    "# ------------------------------------------------------------\n",
    "green_yellow = mcolors.LinearSegmentedColormap.from_list(\n",
    "    \"YellowGreen\", [\"#ffeb3b\", \"#2ca02c\"]   #   0 (yellow)   →   1 (green)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Plot\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "sc = ax.scatter(x, y,\n",
    "                s=14, alpha=0.7,\n",
    "                c=y, cmap=green_yellow, vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xlim(-0.02, 0.02)\n",
    "ax.set_xticks([])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Green fraction  (1=pure green  |  0=pure yellow)\")\n",
    "ax.set_title(\"Eligibility colour spectrum per encounter block\", pad=12)\n",
    "\n",
    "cbar = fig.colorbar(sc, ax=ax, pad=0.02, shrink=0.8)\n",
    "cbar.set_label(\"Green fraction\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.  Caption (automatic wrap)\n",
    "# ------------------------------------------------------------\n",
    "caption = (\n",
    "    \"Each dot = first eligible hour of an encounter block. \"\n",
    "    \"Vertical position/colour show the fraction of satisfied criteria that were \"\n",
    "    \"GREEN (physiologically safer) versus YELLOW (less conservative).\" \n",
    "    \"Horizontal spread is tiny random jitter to avoid over plotting; x -axis has no meaning \"\n",
    ")\n",
    "fig.text(0.01, -0.10, caption, ha=\"left\", va=\"top\", wrap=True, fontsize=9)\n",
    "fig.savefig(f'../output/final/graphs/yellow_eligibility_colour_spectrum_{pyCLIF.helper[\"site_name\"]}.png') \n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0b759",
   "metadata": {
    "papermill": {
     "duration": 0.3196,
     "end_time": "2025-05-05T20:37:23.438518",
     "exception": false,
     "start_time": "2025-05-05T20:37:23.118918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sensitivity analysis: Weekends- WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29985222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad5387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336426b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304c393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b097e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa2267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4aa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1c71c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be37ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c90959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mobilization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.02745,
   "end_time": "2025-05-05T20:37:24.850528",
   "environment_variables": {},
   "exception": null,
   "input_path": "02_mobilization_analysis.ipynb",
   "output_path": "02_mobilization_analysis.ipynb",
   "parameters": {},
   "start_time": "2025-05-05T20:35:53.823078",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
